{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key를 환경변수로 관리하기 위한 설정 파일\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API Key 정보로드\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain_study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm_aya = Ollama(model=\"aya\", temperature=0)\n",
    "llm_llama3 = Ollama(model=\"llama3:instruct\", temperature=0)\n",
    "llm_gemma = Ollama(model=\"gemma\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_gpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    System : 너는 다음 Instruction 을 잘 수행하는 assistant 이다.\n",
    "    Instruction : {instruction}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_aya = prompt | llm_aya | output_parser\n",
    "chain_llama3 = prompt | llm_llama3 | output_parser\n",
    "chain_gemma = prompt | llm_gemma | output_parser\n",
    "chain_gpt = prompt | llm_gpt | output_parser\n",
    "\n",
    "chain_llms = RunnableParallel(aya=chain_aya, gemma=chain_gemma, llama3=chain_llama3, gpt=chain_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aya': 'HOT6는 시원한 탄산수와 달콤한 과일 향이 조화를 이루는 독특한 음료입니다. 이 음료수는 상쾌한 맛과 함께 비타민을 '\n",
      "        '함유하고 있어 건강에도 좋습니다. HOT6는 다양한 과일 향으로 출시되어 있으며, 각기 다른 독특한 맛을 제공합니다. 예를 '\n",
      "        '들어, 자몽과 오렌지 향이 나는 HOT6는 상큼한 맛을, 복숭아와 하트 향이 나는 HOT6는 달콤하고 부드러운 맛을 '\n",
      "        '제공합니다. 이 음료수는 특히 더운 날씨에 갈증 해소와 함께 과일 향을 즐기고 싶을 때 좋습니다. 또한, HOT6는 다양한 '\n",
      "        '패키지 옵션으로 출시되어 있어 편리하게 즐길 수 있습니다.',\n",
      " 'gemma': 'HOT6 라는 음료수는 아마도 HOT CHOCOLATE 라는 음료수를 의미할 것입니다. HOT CHOCOLATE는 '\n",
      "          '초콜릿과 우유를 섞은 음료수입니다.',\n",
      " 'llama3': \"As your assistant, I'd be happy to provide information about \"\n",
      "           'HOT6.\\n'\n",
      "           '\\n'\n",
      "           'HOT6 is a popular Korean energy drink that has gained a '\n",
      "           'significant following worldwide. Here are some key points about '\n",
      "           'HOT6:\\n'\n",
      "           '\\n'\n",
      "           '**Taste:** HOT6 has a unique and refreshing taste profile that '\n",
      "           'combines sweet and sour notes with a hint of citrus.\\n'\n",
      "           '\\n'\n",
      "           '**Ingredients:** The drink contains a blend of natural '\n",
      "           'ingredients, including ginseng, B vitamins, and taurine, which are '\n",
      "           'believed to provide energy-boosting properties.\\n'\n",
      "           '\\n'\n",
      "           '**Caffeine content:** HOT6 contains 80mg of caffeine per serving, '\n",
      "           'which is relatively moderate compared to other energy drinks on '\n",
      "           'the market.\\n'\n",
      "           '\\n'\n",
      "           '**Benefits:** Fans of HOT6 claim that it helps increase their '\n",
      "           'mental clarity, boosts their mood, and provides a natural energy '\n",
      "           'boost without jitters or crashes.\\n'\n",
      "           '\\n'\n",
      "           '**Availability:** HOT6 is widely available in Korea and has gained '\n",
      "           'popularity globally through online retailers and specialty '\n",
      "           'stores.\\n'\n",
      "           '\\n'\n",
      "           'Would you like to know more about HOT6 or perhaps explore other '\n",
      "           'energy drinks? 😊'}\n"
     ]
    }
   ],
   "source": [
    "# chain_llms 실행 Test\n",
    "responses = chain_llms.invoke({\"instruction\":\"HOT6 라는 음료수에 대해 알려주세요.\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    System : \n",
    "    너는 llm model들의 답변을 비교하고 평가하는 AI 이다.\n",
    "    Instruction과 Responses 안의 각각의 llm별 응답을 \n",
    "    정확성(Accuracy), 관련성(Relevance), 유창성(Fluency), 완전성(Completeness) 측면에서    \n",
    "    분석하고 우열을 가려라.\n",
    "    한국어로 답변해줘.\n",
    "\n",
    "    Instruction : {instruction}\n",
    "    Resonses : {responses}\n",
    "    \"\"\",\n",
    "    input_variables=[\"instruction\", \"responses\"],\n",
    "    #partial_variables={\"instruction\" : instruction},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_eval = eval_prompt | llm_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_combinded = (\n",
    "    {\"responses\" : chain_llms, \"instruction\" : RunnablePassthrough()}\n",
    "    | chain_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"argoCD에 대해 알려주세요.\"\n",
    "\n",
    "response = chain_combinded.invoke({\"instruction\":instruction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 LLM 모델의 응답을 분석하고 평가해보겠습니다.\n",
      "\n",
      "### aya\n",
      "**장점:**\n",
      "1. Argo CD의 주요 기능을 상세히 설명함.\n",
      "2. 지속적인 배포, 환경 관리, 동기화 및 복제, 시각적 인터페이스, 작업 흐름 통합 등 다양한 기능을 다룸.\n",
      "3. 구체적인 예시와 함께 설명하여 이해하기 쉽게 작성됨.\n",
      "\n",
      "**단점:**\n",
      "1. 다소 길고 복잡하게 느껴질 수 있음.\n",
      "2. 일부 기능 설명이 중복되거나 불필요하게 자세할 수 있음.\n",
      "\n",
      "### gemma\n",
      "**장점:**\n",
      "1. 간결하고 명확하게 주요 기능을 설명함.\n",
      "2. 자동화된 배포, GitOps 모델, Rolling Deployment, 다양한 플랫폼 지원 등 핵심 기능을 잘 다룸.\n",
      "3. 개발자와 DevOps 엔지니어에게 유용한 도구임을 강조함.\n",
      "\n",
      "**단점:**\n",
      "1. 기능 설명이 다소 간략하여 깊이 있는 이해를 제공하지 못할 수 있음.\n",
      "2. 일부 기능 설명이 부족하거나 생략됨.\n",
      "\n",
      "### llama3\n",
      "**장점:**\n",
      "1. GitOps, Kubernetes-native, Application-centric, Multi-environment support, Rollbacks and rollouts 등 주요 기능을 잘 설명함.\n",
      "2. Argo CD의 이점과 사용 사례를 명확히 제시함.\n",
      "3. 간결하면서도 핵심을 잘 짚어줌.\n",
      "\n",
      "**단점:**\n",
      "1. 일부 용어가 다소 기술적일 수 있어 초보자에게는 어려울 수 있음.\n",
      "2. 한국어가 아닌 영어로 작성되어 있어 한국어 사용자에게는 불편할 수 있음.\n",
      "\n",
      "### gpt\n",
      "**장점:**\n",
      "1. GitOps 기반 배포, 자동 동기화, 롤백 및 히스토리 관리, 다양한 인증 및 권한 관리, 웹 UI 및 CLI, 다양한 배포 전략 지원, 확장성 등 주요 기능을 잘 설명함.\n",
      "2. Argo CD의 장점을 명확히 제시함.\n",
      "3. 간결하면서도 핵심을 잘 짚어줌.\n",
      "\n",
      "**단점:**\n",
      "1. 일부 기능 설명이 다소 간략할 수 있음.\n",
      "2. 기술적인 용어가 많아 초보자에게는 어려울 수 있음.\n",
      "\n",
      "### 종합 평가\n",
      "1. **aya**: 기능 설명이 매우 상세하고 구체적이지만, 다소 길고 복잡할 수 있음.\n",
      "2. **gemma**: 간결하고 명확하지만, 기능 설명이 다소 부족할 수 있음.\n",
      "3. **llama3**: 주요 기능과 이점을 잘 설명하지만, 영어로 작성되어 한국어 사용자에게는 불편할 수 있음.\n",
      "4. **gpt**: 주요 기능과 장점을 잘 설명하며, 간결하고 명확함.\n",
      "\n",
      "**최종 평가:**\n",
      "- **gpt**의 응답이 가장 우수합니다. 주요 기능과 장점을 잘 설명하고 있으며, 간결하면서도 핵심을 잘 짚어줍니다. 다만, 기술적인 용어가 많아 초보자에게는 어려울 수 있지만, 전반적으로 가장 균형 잡힌 설명을 제공합니다.\n",
      "- **aya**의 응답도 매우 상세하고 유용하지만, 다소 길고 복잡할 수 있어 두 번째로 우수합니다.\n",
      "- **gemma**는 간결하고 명확하지만, 기능 설명이 다소 부족하여 세 번째로 평가됩니다.\n",
      "- **llama3**는 영어로 작성되어 한국어 사용자에게는 불편할 수 있어 마지막으로 평가됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
