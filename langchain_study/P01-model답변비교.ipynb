{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API Key ì •ë³´ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain_study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm_aya = Ollama(model=\"aya\", temperature=0)\n",
    "llm_llama3 = Ollama(model=\"llama3:instruct\", temperature=0)\n",
    "llm_gemma = Ollama(model=\"gemma\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_gpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    System : ë„ˆëŠ” ë‹¤ìŒ Instruction ì„ ì˜ ìˆ˜í–‰í•˜ëŠ” assistant ì´ë‹¤.\n",
    "    Instruction : {instruction}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_aya = prompt | llm_aya | output_parser\n",
    "chain_llama3 = prompt | llm_llama3 | output_parser\n",
    "chain_gemma = prompt | llm_gemma | output_parser\n",
    "chain_gpt = prompt | llm_gpt | output_parser\n",
    "\n",
    "chain_llms = RunnableParallel(aya=chain_aya, gemma=chain_gemma, llama3=chain_llama3, gpt=chain_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aya': 'HOT6ëŠ” ì‹œì›í•œ íƒ„ì‚°ìˆ˜ì™€ ë‹¬ì½¤í•œ ê³¼ì¼ í–¥ì´ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë…íŠ¹í•œ ìŒë£Œì…ë‹ˆë‹¤. ì´ ìŒë£Œìˆ˜ëŠ” ìƒì¾Œí•œ ë§›ê³¼ í•¨ê»˜ ë¹„íƒ€ë¯¼ì„ '\n",
      "        'í•¨ìœ í•˜ê³  ìˆì–´ ê±´ê°•ì—ë„ ì¢‹ìŠµë‹ˆë‹¤. HOT6ëŠ” ë‹¤ì–‘í•œ ê³¼ì¼ í–¥ìœ¼ë¡œ ì¶œì‹œë˜ì–´ ìˆìœ¼ë©°, ê°ê¸° ë‹¤ë¥¸ ë…íŠ¹í•œ ë§›ì„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ '\n",
      "        'ë“¤ì–´, ìëª½ê³¼ ì˜¤ë Œì§€ í–¥ì´ ë‚˜ëŠ” HOT6ëŠ” ìƒí¼í•œ ë§›ì„, ë³µìˆ­ì•„ì™€ í•˜íŠ¸ í–¥ì´ ë‚˜ëŠ” HOT6ëŠ” ë‹¬ì½¤í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§›ì„ '\n",
      "        'ì œê³µí•©ë‹ˆë‹¤. ì´ ìŒë£Œìˆ˜ëŠ” íŠ¹íˆ ë”ìš´ ë‚ ì”¨ì— ê°ˆì¦ í•´ì†Œì™€ í•¨ê»˜ ê³¼ì¼ í–¥ì„ ì¦ê¸°ê³  ì‹¶ì„ ë•Œ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ, HOT6ëŠ” ë‹¤ì–‘í•œ '\n",
      "        'íŒ¨í‚¤ì§€ ì˜µì…˜ìœ¼ë¡œ ì¶œì‹œë˜ì–´ ìˆì–´ í¸ë¦¬í•˜ê²Œ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
      " 'gemma': 'HOT6 ë¼ëŠ” ìŒë£Œìˆ˜ëŠ” ì•„ë§ˆë„ HOT CHOCOLATE ë¼ëŠ” ìŒë£Œìˆ˜ë¥¼ ì˜ë¯¸í•  ê²ƒì…ë‹ˆë‹¤. HOT CHOCOLATEëŠ” '\n",
      "          'ì´ˆì½œë¦¿ê³¼ ìš°ìœ ë¥¼ ì„ì€ ìŒë£Œìˆ˜ì…ë‹ˆë‹¤.',\n",
      " 'llama3': \"As your assistant, I'd be happy to provide information about \"\n",
      "           'HOT6.\\n'\n",
      "           '\\n'\n",
      "           'HOT6 is a popular Korean energy drink that has gained a '\n",
      "           'significant following worldwide. Here are some key points about '\n",
      "           'HOT6:\\n'\n",
      "           '\\n'\n",
      "           '**Taste:** HOT6 has a unique and refreshing taste profile that '\n",
      "           'combines sweet and sour notes with a hint of citrus.\\n'\n",
      "           '\\n'\n",
      "           '**Ingredients:** The drink contains a blend of natural '\n",
      "           'ingredients, including ginseng, B vitamins, and taurine, which are '\n",
      "           'believed to provide energy-boosting properties.\\n'\n",
      "           '\\n'\n",
      "           '**Caffeine content:** HOT6 contains 80mg of caffeine per serving, '\n",
      "           'which is relatively moderate compared to other energy drinks on '\n",
      "           'the market.\\n'\n",
      "           '\\n'\n",
      "           '**Benefits:** Fans of HOT6 claim that it helps increase their '\n",
      "           'mental clarity, boosts their mood, and provides a natural energy '\n",
      "           'boost without jitters or crashes.\\n'\n",
      "           '\\n'\n",
      "           '**Availability:** HOT6 is widely available in Korea and has gained '\n",
      "           'popularity globally through online retailers and specialty '\n",
      "           'stores.\\n'\n",
      "           '\\n'\n",
      "           'Would you like to know more about HOT6 or perhaps explore other '\n",
      "           'energy drinks? ğŸ˜Š'}\n"
     ]
    }
   ],
   "source": [
    "# chain_llms ì‹¤í–‰ Test\n",
    "responses = chain_llms.invoke({\"instruction\":\"HOT6 ë¼ëŠ” ìŒë£Œìˆ˜ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    System : \n",
    "    ë„ˆëŠ” llm modelë“¤ì˜ ë‹µë³€ì„ ë¹„êµí•˜ê³  í‰ê°€í•˜ëŠ” AI ì´ë‹¤.\n",
    "    Instructionê³¼ Responses ì•ˆì˜ ê°ê°ì˜ llmë³„ ì‘ë‹µì„ \n",
    "    ì •í™•ì„±(Accuracy), ê´€ë ¨ì„±(Relevance), ìœ ì°½ì„±(Fluency), ì™„ì „ì„±(Completeness) ì¸¡ë©´ì—ì„œ    \n",
    "    ë¶„ì„í•˜ê³  ìš°ì—´ì„ ê°€ë ¤ë¼.\n",
    "    í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜.\n",
    "\n",
    "    Instruction : {instruction}\n",
    "    Resonses : {responses}\n",
    "    \"\"\",\n",
    "    input_variables=[\"instruction\", \"responses\"],\n",
    "    #partial_variables={\"instruction\" : instruction},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_eval = eval_prompt | llm_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_combinded = (\n",
    "    {\"responses\" : chain_llms, \"instruction\" : RunnablePassthrough()}\n",
    "    | chain_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"argoCDì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "\n",
    "response = chain_combinded.invoke({\"instruction\":instruction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê° LLM ëª¨ë¸ì˜ ì‘ë‹µì„ ë¶„ì„í•˜ê³  í‰ê°€í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### aya\n",
      "**ì¥ì :**\n",
      "1. Argo CDì˜ ì£¼ìš” ê¸°ëŠ¥ì„ ìƒì„¸íˆ ì„¤ëª…í•¨.\n",
      "2. ì§€ì†ì ì¸ ë°°í¬, í™˜ê²½ ê´€ë¦¬, ë™ê¸°í™” ë° ë³µì œ, ì‹œê°ì  ì¸í„°í˜ì´ìŠ¤, ì‘ì—… íë¦„ í†µí•© ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ë‹¤ë£¸.\n",
      "3. êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ì—¬ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±ë¨.\n",
      "\n",
      "**ë‹¨ì :**\n",
      "1. ë‹¤ì†Œ ê¸¸ê³  ë³µì¡í•˜ê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆìŒ.\n",
      "2. ì¼ë¶€ ê¸°ëŠ¥ ì„¤ëª…ì´ ì¤‘ë³µë˜ê±°ë‚˜ ë¶ˆí•„ìš”í•˜ê²Œ ìì„¸í•  ìˆ˜ ìˆìŒ.\n",
      "\n",
      "### gemma\n",
      "**ì¥ì :**\n",
      "1. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì£¼ìš” ê¸°ëŠ¥ì„ ì„¤ëª…í•¨.\n",
      "2. ìë™í™”ëœ ë°°í¬, GitOps ëª¨ë¸, Rolling Deployment, ë‹¤ì–‘í•œ í”Œë«í¼ ì§€ì› ë“± í•µì‹¬ ê¸°ëŠ¥ì„ ì˜ ë‹¤ë£¸.\n",
      "3. ê°œë°œìì™€ DevOps ì—”ì§€ë‹ˆì–´ì—ê²Œ ìœ ìš©í•œ ë„êµ¬ì„ì„ ê°•ì¡°í•¨.\n",
      "\n",
      "**ë‹¨ì :**\n",
      "1. ê¸°ëŠ¥ ì„¤ëª…ì´ ë‹¤ì†Œ ê°„ëµí•˜ì—¬ ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ ì œê³µí•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ.\n",
      "2. ì¼ë¶€ ê¸°ëŠ¥ ì„¤ëª…ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ìƒëµë¨.\n",
      "\n",
      "### llama3\n",
      "**ì¥ì :**\n",
      "1. GitOps, Kubernetes-native, Application-centric, Multi-environment support, Rollbacks and rollouts ë“± ì£¼ìš” ê¸°ëŠ¥ì„ ì˜ ì„¤ëª…í•¨.\n",
      "2. Argo CDì˜ ì´ì ê³¼ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ëª…í™•íˆ ì œì‹œí•¨.\n",
      "3. ê°„ê²°í•˜ë©´ì„œë„ í•µì‹¬ì„ ì˜ ì§šì–´ì¤Œ.\n",
      "\n",
      "**ë‹¨ì :**\n",
      "1. ì¼ë¶€ ìš©ì–´ê°€ ë‹¤ì†Œ ê¸°ìˆ ì ì¼ ìˆ˜ ìˆì–´ ì´ˆë³´ìì—ê²ŒëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ.\n",
      "2. í•œêµ­ì–´ê°€ ì•„ë‹Œ ì˜ì–´ë¡œ ì‘ì„±ë˜ì–´ ìˆì–´ í•œêµ­ì–´ ì‚¬ìš©ìì—ê²ŒëŠ” ë¶ˆí¸í•  ìˆ˜ ìˆìŒ.\n",
      "\n",
      "### gpt\n",
      "**ì¥ì :**\n",
      "1. GitOps ê¸°ë°˜ ë°°í¬, ìë™ ë™ê¸°í™”, ë¡¤ë°± ë° íˆìŠ¤í† ë¦¬ ê´€ë¦¬, ë‹¤ì–‘í•œ ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬, ì›¹ UI ë° CLI, ë‹¤ì–‘í•œ ë°°í¬ ì „ëµ ì§€ì›, í™•ì¥ì„± ë“± ì£¼ìš” ê¸°ëŠ¥ì„ ì˜ ì„¤ëª…í•¨.\n",
      "2. Argo CDì˜ ì¥ì ì„ ëª…í™•íˆ ì œì‹œí•¨.\n",
      "3. ê°„ê²°í•˜ë©´ì„œë„ í•µì‹¬ì„ ì˜ ì§šì–´ì¤Œ.\n",
      "\n",
      "**ë‹¨ì :**\n",
      "1. ì¼ë¶€ ê¸°ëŠ¥ ì„¤ëª…ì´ ë‹¤ì†Œ ê°„ëµí•  ìˆ˜ ìˆìŒ.\n",
      "2. ê¸°ìˆ ì ì¸ ìš©ì–´ê°€ ë§ì•„ ì´ˆë³´ìì—ê²ŒëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ.\n",
      "\n",
      "### ì¢…í•© í‰ê°€\n",
      "1. **aya**: ê¸°ëŠ¥ ì„¤ëª…ì´ ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ì´ì§€ë§Œ, ë‹¤ì†Œ ê¸¸ê³  ë³µì¡í•  ìˆ˜ ìˆìŒ.\n",
      "2. **gemma**: ê°„ê²°í•˜ê³  ëª…í™•í•˜ì§€ë§Œ, ê¸°ëŠ¥ ì„¤ëª…ì´ ë‹¤ì†Œ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ.\n",
      "3. **llama3**: ì£¼ìš” ê¸°ëŠ¥ê³¼ ì´ì ì„ ì˜ ì„¤ëª…í•˜ì§€ë§Œ, ì˜ì–´ë¡œ ì‘ì„±ë˜ì–´ í•œêµ­ì–´ ì‚¬ìš©ìì—ê²ŒëŠ” ë¶ˆí¸í•  ìˆ˜ ìˆìŒ.\n",
      "4. **gpt**: ì£¼ìš” ê¸°ëŠ¥ê³¼ ì¥ì ì„ ì˜ ì„¤ëª…í•˜ë©°, ê°„ê²°í•˜ê³  ëª…í™•í•¨.\n",
      "\n",
      "**ìµœì¢… í‰ê°€:**\n",
      "- **gpt**ì˜ ì‘ë‹µì´ ê°€ì¥ ìš°ìˆ˜í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ëŠ¥ê³¼ ì¥ì ì„ ì˜ ì„¤ëª…í•˜ê³  ìˆìœ¼ë©°, ê°„ê²°í•˜ë©´ì„œë„ í•µì‹¬ì„ ì˜ ì§šì–´ì¤ë‹ˆë‹¤. ë‹¤ë§Œ, ê¸°ìˆ ì ì¸ ìš©ì–´ê°€ ë§ì•„ ì´ˆë³´ìì—ê²ŒëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆì§€ë§Œ, ì „ë°˜ì ìœ¼ë¡œ ê°€ì¥ ê· í˜• ì¡íŒ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "- **aya**ì˜ ì‘ë‹µë„ ë§¤ìš° ìƒì„¸í•˜ê³  ìœ ìš©í•˜ì§€ë§Œ, ë‹¤ì†Œ ê¸¸ê³  ë³µì¡í•  ìˆ˜ ìˆì–´ ë‘ ë²ˆì§¸ë¡œ ìš°ìˆ˜í•©ë‹ˆë‹¤.\n",
      "- **gemma**ëŠ” ê°„ê²°í•˜ê³  ëª…í™•í•˜ì§€ë§Œ, ê¸°ëŠ¥ ì„¤ëª…ì´ ë‹¤ì†Œ ë¶€ì¡±í•˜ì—¬ ì„¸ ë²ˆì§¸ë¡œ í‰ê°€ë©ë‹ˆë‹¤.\n",
      "- **llama3**ëŠ” ì˜ì–´ë¡œ ì‘ì„±ë˜ì–´ í•œêµ­ì–´ ì‚¬ìš©ìì—ê²ŒëŠ” ë¶ˆí¸í•  ìˆ˜ ìˆì–´ ë§ˆì§€ë§‰ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
