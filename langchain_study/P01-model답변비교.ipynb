{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API Key ì •ë³´ë¡œë“œ\n",
    "# - OPENAI_API_KEY = \"\"\n",
    "# - LANGCHAIN_TRACING_V2 = \"true\"\n",
    "# - LANGCHAIN_ENDPOINT = \"https://api.smith.langchain.com\"\n",
    "# - LANGCHAIN_API_KEY = \"\"\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain_study\" # Langsmith project ëª…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµëŒ€ìƒ ëª¨ë¸ID ìƒìˆ˜ ì •ì˜\n",
    "IS_HOME = False\n",
    "\n",
    "if IS_HOME:\n",
    "    AYA = \"aya:8b-23-q8_0\"\n",
    "    LLAMA3 = \"llama3:8b-instruct-q8_0\"\n",
    "    GEMMA = \"gemma:7b-instruct-q8_0\"\n",
    "    PHI3 = \"phi3:instruct\"\n",
    "else:\n",
    "    AYA = \"aya\"\n",
    "    LLAMA3 = \"llama3:instruct\"\n",
    "    GEMMA = \"gemma\"\n",
    "    PHI3 = \"phi3:instruct\"\n",
    "\n",
    "GPT = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm_aya = Ollama(model=AYA, temperature=0)\n",
    "llm_llama3 = Ollama(model=LLAMA3, temperature=0)\n",
    "llm_gemma = Ollama(model=GEMMA, temperature=0)\n",
    "llm_phi3 = Ollama(model=PHI3, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_gpt = ChatOpenAI(model=GPT, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    System : ë„ˆëŠ” ë‹¤ìŒ Instructionì„ ì˜ ìˆ˜í–‰í•˜ëŠ” assistant ì´ë‹¤.\n",
    "    Instruction : {instruction}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_aya = prompt | llm_aya | output_parser\n",
    "chain_llama3 = prompt | llm_llama3 | output_parser\n",
    "chain_gemma = prompt | llm_gemma | output_parser\n",
    "chain_phi3 = prompt | llm_phi3 | output_parser\n",
    "chain_gpt = prompt | llm_gpt | output_parser\n",
    "\n",
    "param = {\n",
    "    AYA : chain_aya ,\n",
    "    LLAMA3 : chain_llama3 ,\n",
    "    GEMMA : chain_gemma ,\n",
    "    PHI3 : chain_phi3 ,\n",
    "    GPT : chain_gpt ,\n",
    "}\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain_llms = RunnableParallel(**param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (TEST) í‰ê°€ëŒ€ìƒ LLM ë¬¸ì œ ì¶œì œ ë° ë‹µì•ˆ ì‘ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aya': 'ì‹í˜œëŠ” í•œêµ­ì˜ ì „í†µ ìŒë£Œë¡œ, ìŒ€ë¡œ ë§Œë“  ì‹œëŸ½ì´ë‚˜ ê¿€ë¡œ ë‹¨ë§›ì„ ë‚´ê³  ë•Œë•Œë¡œ ë§ˆëŠ˜ì´ë‚˜ ìƒê°•ê³¼ ê°™ì€ í–¥ì‹ ë£Œë¥¼ ë„£ì–´ ë§Œë“­ë‹ˆë‹¤. '\n",
      "        'ê·¸ê²ƒì€ ì¢…ì¢… ì°¨ê°€ìš´ ìƒíƒœë¡œ ì œê³µë˜ë©°, ë‹¬ì½¤í•˜ê³  ì•½ê°„ ë§¤ì½¤í•œ ë§›ì´ ë‚©ë‹ˆë‹¤. ì‹í˜œëŠ” í•œêµ­ ë¬¸í™”ì—ì„œ ì¸ê¸° ìˆëŠ” ìŒë£Œì´ë©°, íŠ¹íˆ '\n",
      "        'ì—¬ë¦„ì— ì¸ê¸°ê°€ ë§ìŠµë‹ˆë‹¤. ê·¸ê²ƒì€ ì¢…ì¢… ê±´ê°• ì¦ì§„ê³¼ ì†Œí™” ê°œì„ ì— ë„ì›€ì´ ë˜ëŠ” ê²ƒìœ¼ë¡œ ì—¬ê²¨ì§‘ë‹ˆë‹¤.',\n",
      " 'gemma': 'ì‹í˜œëŠ” í•œêµ­ì—ì„œ ìœ ëª…í•œ ìŒë£Œìˆ˜ì…ë‹ˆë‹¤. ì£¼ë¡œ ê³¼ì¼, íŠ¹íˆ ì‚¬ê³¼ë¥¼ ì£¼ì›ìœ¼ë¡œ í•˜ê³ , ì„¤íƒ•ê³¼ í–¥ì´ ë“¤ì–´ê°„ ìŒë£Œì…ë‹ˆë‹¤. ì‹í˜œëŠ” '\n",
      "          'ê±´ê°•ì— ë„ì›€ì´ ë˜ê³ , íŠ¹íˆ ì—¬ë¦„ì— ë§ˆì…”ë©´ ì‹ ì„ ê°ì„ ëŠë¼ê³  íœ´ì‹ì„ ì·¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
      " 'gpt-4o': 'ì‹í˜œëŠ” í•œêµ­ì˜ ì „í†µ ìŒë£Œìˆ˜ë¡œ, ì£¼ë¡œ ìŒ€ê³¼ ì—¿ê¸°ë¦„ì„ ì‚¬ìš©í•˜ì—¬ ë§Œë“­ë‹ˆë‹¤. ì‹í˜œëŠ” ë‹¬ì½¤í•˜ê³  ì‹œì›í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, íŠ¹íˆ '\n",
      "           'ëª…ì ˆì´ë‚˜ íŠ¹ë³„í•œ í–‰ì‚¬ì—ì„œ ìì£¼ ì¦ê²¨ ë§ˆì‹­ë‹ˆë‹¤. ë‹¤ìŒì€ ì‹í˜œì— ëŒ€í•œ ì£¼ìš” ì •ë³´ì…ë‹ˆë‹¤:\\n'\n",
      "           '\\n'\n",
      "           '1. **ì¬ë£Œ**:\\n'\n",
      "           '   - **ìŒ€**: ì£¼ë¡œ ì°¹ìŒ€ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ë©¥ìŒ€ì„ ì‚¬ìš©í•˜ê¸°ë„ í•©ë‹ˆë‹¤.\\n'\n",
      "           '   - **ì—¿ê¸°ë¦„**: ì—¿ê¸°ë¦„ ê°€ë£¨ë¥¼ ë¬¼ì— ìš°ë ¤ë‚´ì–´ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n'\n",
      "           '   - **ì„¤íƒ•**: ë‹¨ë§›ì„ ë”í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n'\n",
      "           '   - **ë¬¼**: ê¸°ë³¸ì ì¸ ì¬ë£Œë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n'\n",
      "           '\\n'\n",
      "           '2. **ë§Œë“œëŠ” ë°©ë²•**:\\n'\n",
      "           '   1. ì—¿ê¸°ë¦„ ê°€ë£¨ë¥¼ ë¬¼ì— ë„£ê³  ì˜ ì„ì€ í›„, ì²´ì— ê±¸ëŸ¬ ì—¿ê¸°ë¦„ ë¬¼ì„ ë§Œë“­ë‹ˆë‹¤.\\n'\n",
      "           '   2. ì°¹ìŒ€ì„ ì”»ì–´ ë¬¼ì— ë¶ˆë¦° í›„, ë°¥ì„ ì§“ìŠµë‹ˆë‹¤.\\n'\n",
      "           '   3. ì§€ì€ ë°¥ì„ ì—¿ê¸°ë¦„ ë¬¼ì— ë„£ê³  ì¼ì • ì‹œê°„ ë™ì•ˆ ë°œíš¨ì‹œí‚µë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ë°¥ì•Œì´ ë– ì˜¤ë¥´ë©´ ë°œíš¨ê°€ ì˜ ëœ '\n",
      "           'ê²ƒì…ë‹ˆë‹¤.\\n'\n",
      "           '   4. ë°œíš¨ê°€ ëë‚˜ë©´ ë°¥ì•Œì„ ê±´ì ¸ë‚´ê³ , ì„¤íƒ•ì„ ë„£ì–´ ë‹¨ë§›ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\\n'\n",
      "           '   5. ì‹í˜œë¥¼ ëƒ‰ì¥ê³ ì— ë„£ì–´ ì‹œì›í•˜ê²Œ í•œ í›„, ë– ì˜¤ë¥¸ ë°¥ì•Œê³¼ í•¨ê»˜ ì„œë¹™í•©ë‹ˆë‹¤.\\n'\n",
      "           '\\n'\n",
      "           '3. **íš¨ëŠ¥**:\\n'\n",
      "           '   - ì†Œí™”ë¥¼ ë•ëŠ” íš¨ëŠ¥ì´ ìˆì–´ ì‹í›„ ìŒë£Œë¡œ ì¢‹ìŠµë‹ˆë‹¤.\\n'\n",
      "           '   - ì—¿ê¸°ë¦„ì— í¬í•¨ëœ íš¨ì†Œê°€ ì†Œí™” ì‘ìš©ì„ ë„ì™€ì¤ë‹ˆë‹¤.\\n'\n",
      "           '   - ê°ˆì¦ í•´ì†Œì— íš¨ê³¼ì ì…ë‹ˆë‹¤.\\n'\n",
      "           '\\n'\n",
      "           '4. **ë¬¸í™”ì  ì˜ë¯¸**:\\n'\n",
      "           '   - ì‹í˜œëŠ” í•œêµ­ì˜ ì „í†µ ëª…ì ˆì¸ ì„¤ë‚ ê³¼ ì¶”ì„ì— ìì£¼ ë§ˆì‹œëŠ” ìŒë£Œì…ë‹ˆë‹¤.\\n'\n",
      "           '   - ì „í†µì ìœ¼ë¡œ ê°€ì •ì—ì„œ ì§ì ‘ ë§Œë“¤ì–´ ë§ˆì‹œê¸°ë„ í•˜ì§€ë§Œ, í˜„ëŒ€ì—ëŠ” ìƒì ì—ì„œ ì‰½ê²Œ êµ¬ì…í•  ìˆ˜ ìˆëŠ” ì œí’ˆë„ ë§ì´ ë‚˜ì™€ '\n",
      "           'ìˆìŠµë‹ˆë‹¤.\\n'\n",
      "           '\\n'\n",
      "           'ì‹í˜œëŠ” ê·¸ ë…íŠ¹í•œ ë§›ê³¼ í–¥ìœ¼ë¡œ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ì‚¬ë‘ë°›ëŠ” ìŒë£Œì…ë‹ˆë‹¤. ì‹œì›í•˜ê²Œ ë§ˆì‹œë©´ ë”ìš± ë§›ìˆìœ¼ë©°, íŠ¹íˆ ë”ìš´ ì—¬ë¦„ì² ì— '\n",
      "           'ì¸ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.',\n",
      " 'llama3:instruct': 'ğŸ˜Š\\n'\n",
      "                    '\\n'\n",
      "                    'So, you want to know about Sikhye (ì‹í˜œ), a traditional '\n",
      "                    'Korean drink. Sikhye is a sweet, fermented rice drink '\n",
      "                    \"that has been enjoyed for centuries in Korea. Here's what \"\n",
      "                    'I can tell you about it:\\n'\n",
      "                    '\\n'\n",
      "                    '**What is Sikhye?**\\n'\n",
      "                    'Sikhye is a type of Korean beverage made from fermented '\n",
      "                    'glutinous rice and various flavorings such as sugar, '\n",
      "                    'honey, or fruit extracts. The fermentation process gives '\n",
      "                    'the drink its unique sweet and slightly sour taste.\\n'\n",
      "                    '\\n'\n",
      "                    '**History**\\n'\n",
      "                    'Sikhye has been a part of Korean culture for over 1,000 '\n",
      "                    'years. It was originally consumed by royalty and nobles, '\n",
      "                    'but later became popular among common people as well. '\n",
      "                    'Sikhye was often served at special occasions like '\n",
      "                    'weddings and holidays.\\n'\n",
      "                    '\\n'\n",
      "                    '**Taste and Texture**\\n'\n",
      "                    'The taste of Sikhye is sweet and slightly sour, with a '\n",
      "                    'hint of fermentation flavor. The texture is thick and '\n",
      "                    'syrupy, similar to honey or molasses.\\n'\n",
      "                    '\\n'\n",
      "                    '**Variations**\\n'\n",
      "                    'There are many variations of Sikhye, depending on the '\n",
      "                    'type of rice used, the level of fermentation, and the '\n",
      "                    'added flavorings. Some common flavors include:\\n'\n",
      "                    '\\n'\n",
      "                    '* Original: Made with glutinous rice and sugar\\n'\n",
      "                    '* Fruit-flavored: Infused with fruit extracts like '\n",
      "                    'strawberry, orange, or grapefruit\\n'\n",
      "                    '* Honey-flavored: Made with honey instead of sugar\\n'\n",
      "                    '* Spiced: Adds spices like cinnamon, ginger, or nutmeg '\n",
      "                    'for extra flavor\\n'\n",
      "                    '\\n'\n",
      "                    '**Health Benefits**\\n'\n",
      "                    'Sikhye is believed to have several health benefits, '\n",
      "                    'including:\\n'\n",
      "                    '\\n'\n",
      "                    '* Aiding digestion and relieving stomach discomfort\\n'\n",
      "                    '* Providing antioxidants and vitamins\\n'\n",
      "                    '* Helping to regulate blood sugar levels\\n'\n",
      "                    '\\n'\n",
      "                    '**How to Enjoy Sikhye**\\n'\n",
      "                    'Sikhye can be enjoyed on its own as a refreshing drink or '\n",
      "                    \"used as an ingredient in cooking. It's often served warm \"\n",
      "                    'during the winter months, but it can also be chilled for '\n",
      "                    'a summer treat.\\n'\n",
      "                    '\\n'\n",
      "                    'I hope this helps you understand more about Sikhye! Do '\n",
      "                    'you have any specific questions or would you like to know '\n",
      "                    'more about Korean culture and traditions? ğŸ˜Š',\n",
      " 'phi3:instruct': ' ì‹í˜œë¼ëŠ” ìŒë£Œìˆ˜ì€ í•œêµ­ì˜ ê³ ìœ ì…ë‹ˆë‹¤. ì´ ìŒë£Œìˆ˜ëŠ” ì²­ì‚°ë¬¼ê³¼ ê°™ì€ ë§¨ë°”ë¦¬ë¥¼ ê¸°ë¥´ê¸° ìœ„í•´ ì‚¬ì—°í™” ì†Œí™”ë¬¼ë¡œ, '\n",
      "                  'ë”°ë¼ì„œ ì²­ì‚°ë¬¼ê³¼ ê°™ì€ ì˜í–¥ì„ ì£¼ëŠ” í•©ì„±ë¬¼ì…ë‹ˆë‹¤. ì‹í˜œë¼ì˜ ê¸°íƒ€ ì •ë³´ëŠ” ë‹¤ìŒìœ¼ë¡œ ì„¤ëª…ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\\n'\n",
      "                  '\\n'\n",
      "                  '- í™”í•™ ì´ë¦„: ì†Œí™”ë¬¼ ê·¼ë¹„\\n'\n",
      "                  '- ê°€ìŠ¤ ìœ í´ë¦¬ë“œ ìˆ˜ì¹˜: 1.02\\n'\n",
      "                  '- ì‹œë„ ìœ íƒ±ì: ì²­ì‚°ë¬¼\\n'\n",
      "                  '- ê¸°íƒ€ ì •ë³´: ì‹í˜œë¼ëŠ” í•œêµ­ì˜ ê³ ìœ ì…ë‹ˆë‹¤. ì´ ìŒë£Œìˆ˜ëŠ” ì²­ì‚°ë¬¼ê³¼ ê°™ì€ ì˜í–¥ì„ ì£¼ëŠ” í•©ì„±ë¬¼ì…ë‹ˆë‹¤.\\n'\n",
      "                  '\\n'\n",
      "                  'ì‹í˜œë¼ëŠ” í•œêµ­ì˜ ê³ ìœ ì…ë‹ˆë‹¤, ì²­ì‚°ë¬¼ê³¼ ê°™ì€ ì˜í–¥ì„ ì£¼ëŠ” í•©ì„±ë¬¼ì´ë©°, ì†Œí™”ë¬¼ ê·¼ë¹„ë¥¼ ê°€ì§„ í™”í•™ ì´ë¦„ì¸ ì†Œí™”ë¬¼ '\n",
      "                  'ê·¼ë¹„ì…ë‹ˆë‹¤. ì‹í˜œë¼ì˜ ìœ í´ë¦¬ë“œ ìˆ˜ì¹˜ëŠ” 1.02ì…ë‹ˆë‹¤.\\n'\n",
      "                  '\\n'\n",
      "                  'ë˜í•œ, ì‹í˜œë¼ëŠ” ìŒë£Œìˆ˜ê°€ ì£¼ë¡œ í•œêµ­ì—ì„œ ì‚¬ìš©ë˜ì–´ ìˆëŠ” ìŒë£Œìˆ˜ë¡œ, ì¼ë¶€ ìŒì‹ì—ì„œ ì‚¬ìš©ë˜ëŠ” í•©ì„±ë¬¼ì´ë©°, '\n",
      "                  'ì²­ì‚°ë¬¼ê³¼ ê°™ì€ ì˜í–¥ì„ ì£¼ëŠ” í•©ì„±ë¬¼ì…ë‹ˆë‹¤.\\n'\n",
      "                  ' Written in'}\n"
     ]
    }
   ],
   "source": [
    "# chain_llms ì‹¤í–‰ Test\n",
    "responses = chain_llms.invoke({\"instruction\":\"ì‹í˜œë¼ëŠ” ìŒë£Œìˆ˜ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instruction = \"1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "instruction = \"ë¯¸êµ­ ì†Œë ¨ ëƒ‰ì „ì‹œëŒ€ ë•Œ ì¿ ë°”ìœ„ê¸°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE # 1. StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    System : \n",
    "    ë„ˆëŠ” llm modelë“¤ì˜ ë‹µë³€ì„ ë¹„êµí•˜ê³  í‰ê°€í•˜ëŠ” AI ì´ë‹¤.\n",
    "    Instructionê³¼ Responses ì•ˆì˜ ê°ê°ì˜ llmë³„ ì‘ë‹µì„ \n",
    "    ì •í™•ì„±(Accuracy), ê´€ë ¨ì„±(Relevance), ìœ ì°½ì„±(Fluency), ì™„ì „ì„±(Completeness) ì¸¡ë©´ì—ì„œ    \n",
    "    ë¶„ì„í•˜ê³  ìµœê³  ì ìˆ˜ 5ì ìœ¼ë¡œ 0ì  ~ 5ì  ì‚¬ì´ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ë¼.\n",
    "\n",
    "    í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜.\n",
    "\n",
    "    Instruction : {instruction}\n",
    "    Resonses : {responses}\n",
    "    \"\"\",\n",
    "    input_variables=[\"instruction\", \"responses\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain_combinded = (\n",
    "    {\"responses\" : chain_llms, \"instruction\" : RunnablePassthrough()}\n",
    "    | eval_prompt\n",
    "    | llm_gpt\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì‹¤í–‰(invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### í‰ê°€ ê¸°ì¤€\n",
      "1. **ì •í™•ì„±(Accuracy)**: ì œê³µëœ ì •ë³´ê°€ ì‚¬ì‹¤ì— ê·¼ê±°í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€.\n",
      "2. **ê´€ë ¨ì„±(Relevance)**: ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€.\n",
      "3. **ìœ ì°½ì„±(Fluency)**: ë¬¸ì¥ì´ ì–¼ë§ˆë‚˜ ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ì§€.\n",
      "4. **ì™„ì „ì„±(Completeness)**: ë‹µë³€ì´ ì–¼ë§ˆë‚˜ í¬ê´„ì ì´ê³  ì™„ì „í•œì§€.\n",
      "\n",
      "### í‰ê°€\n",
      "\n",
      "#### aya\n",
      "- **ì •í™•ì„±**: 3ì \n",
      "  - ì¼ë¶€ ê³¡ê³¼ ê°€ìˆ˜ ì •ë³´ê°€ ë¶€ì •í™•í•¨. ì˜ˆë¥¼ ë“¤ì–´, \"ë„¤ë²„ì—”ë”© ìŠ¤í† ë¦¬\"ëŠ” ìœ ì¬í•˜ì˜ ê³¡ì´ ì•„ë‹ˆë©°, \"ì •ê¸€ì˜ ë²•ì¹™\"ì€ ë‘ ë²ˆì§¸ ë‹¬ì˜ ê³¡ì´ ì•„ë‹˜.\n",
      "- **ê´€ë ¨ì„±**: 4ì \n",
      "  - 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì œê³µí•¨.\n",
      "- **ìœ ì°½ì„±**: 4ì \n",
      "  - ë¬¸ì¥ì´ ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ì›€.\n",
      "- **ì™„ì „ì„±**: 4ì \n",
      "  - ë‹¤ì–‘í•œ ì¥ë¥´ì™€ ê°€ìˆ˜ë¥¼ ì–¸ê¸‰í•˜ë©° í¬ê´„ì ì¸ ì •ë³´ë¥¼ ì œê³µí•¨.\n",
      "\n",
      "**ì´ì : 15ì **\n",
      "\n",
      "#### llama3:instruct\n",
      "- **ì •í™•ì„±**: 4ì \n",
      "  - ëŒ€ë¶€ë¶„ì˜ ì •ë³´ê°€ ì •í™•í•˜ì§€ë§Œ, ì¼ë¶€ ì„¸ë¶€ì‚¬í•­ì´ ë¶€ì¡±í•¨.\n",
      "- **ê´€ë ¨ì„±**: 4ì \n",
      "  - 1990ë…„ëŒ€ K-popì— ëŒ€í•œ ì „ë°˜ì ì¸ ì •ë³´ë¥¼ ì œê³µí•¨.\n",
      "- **ìœ ì°½ì„±**: 5ì \n",
      "  - ë¬¸ì¥ì´ ë§¤ìš° ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ì›€.\n",
      "- **ì™„ì „ì„±**: 4ì \n",
      "  - ì£¼ìš” ì•„í‹°ìŠ¤íŠ¸ì™€ ê·¸ë£¹ì„ ì–¸ê¸‰í•˜ë©° í¬ê´„ì ì¸ ì •ë³´ë¥¼ ì œê³µí•¨.\n",
      "\n",
      "**ì´ì : 17ì **\n",
      "\n",
      "#### gemma\n",
      "- **ì •í™•ì„±**: 3ì \n",
      "  - ì¼ë¶€ ê°€ìˆ˜ì™€ ì¥ë¥´ ì •ë³´ê°€ ë¶€ì •í™•í•¨. ì˜ˆë¥¼ ë“¤ì–´, \"SGì›Œë“œ\"ì™€ \"ì´ë””ì•„\"ëŠ” ì˜ ì•Œë ¤ì§€ì§€ ì•Šì€ ê°€ìˆ˜ì„.\n",
      "- **ê´€ë ¨ì„±**: 3ì \n",
      "  - 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ë§Œ, ì„¸ë¶€ì‚¬í•­ì´ ë¶€ì¡±í•¨.\n",
      "- **ìœ ì°½ì„±**: 4ì \n",
      "  - ë¬¸ì¥ì´ ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ì›€.\n",
      "- **ì™„ì „ì„±**: 3ì \n",
      "  - ì£¼ìš” ê°€ìˆ˜ì™€ ì¥ë¥´ë¥¼ ì–¸ê¸‰í•˜ì§€ë§Œ, ì •ë³´ê°€ ë‹¤ì†Œ ì œí•œì ì„.\n",
      "\n",
      "**ì´ì : 13ì **\n",
      "\n",
      "#### gpt-4o\n",
      "- **ì •í™•ì„±**: 5ì \n",
      "  - ì œê³µëœ ì •ë³´ê°€ ë§¤ìš° ì •í™•í•¨.\n",
      "- **ê´€ë ¨ì„±**: 5ì \n",
      "  - 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•œ ë§¤ìš° ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë¥¼ ì œê³µí•¨.\n",
      "- **ìœ ì°½ì„±**: 5ì \n",
      "  - ë¬¸ì¥ì´ ë§¤ìš° ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ì›€.\n",
      "- **ì™„ì „ì„±**: 5ì \n",
      "  - ë‹¤ì–‘í•œ ì¥ë¥´ì™€ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì–¸ê¸‰í•˜ë©° í¬ê´„ì ì¸ ì •ë³´ë¥¼ ì œê³µí•¨.\n",
      "\n",
      "**ì´ì : 20ì **\n",
      "\n",
      "### ê²°ë¡ \n",
      "- **gpt-4o**ê°€ ê°€ì¥ ë†’ì€ ì ìˆ˜(20ì )ë¥¼ ë°›ì•˜ìœ¼ë©°, 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•œ ê°€ì¥ ì •í™•í•˜ê³  í¬ê´„ì ì¸ ì •ë³´ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤.\n",
      "- **llama3:instruct**ëŠ” 17ì ìœ¼ë¡œ ê·¸ ë’¤ë¥¼ ì´ì—ˆìœ¼ë©°, ìœ ì°½ì„±ê³¼ ê´€ë ¨ì„±ì—ì„œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\n",
      "- **aya**ëŠ” 15ì ìœ¼ë¡œ, ì¼ë¶€ ë¶€ì •í™•í•œ ì •ë³´ê°€ ìˆì—ˆì§€ë§Œ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ë‹µë³€ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.\n",
      "- **gemma**ëŠ” 13ì ìœ¼ë¡œ, ì •ë³´ì˜ ì •í™•ì„±ê³¼ ì™„ì „ì„±ì—ì„œ ë‹¤ì†Œ ë¶€ì¡±í•œ ë©´ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = chain_combinded.invoke({\"instruction\":instruction})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE # 2. PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class EvaluationByModel(BaseModel):\n",
    "    model_id: str = Field(description=\"LLM ëª¨ë¸ ì´ë¦„ ë˜ëŠ” LLM ëª¨ë¸ ID\")\n",
    "    accuracy_eval: str = Field(description=\"ì •í™•ì„±(Accuracy) í‰ê°€\")\n",
    "    accuracy_score: int = Field(description=\"ì •í™•ì„±(Accuracy) í‰ê°€ ì ìˆ˜\")\n",
    "    relevance_eval: str = Field(description=\"ê´€ë ¨ì„±(Relevance) í‰ê°€\")\n",
    "    relevance_score: int = Field(description=\"ê´€ë ¨ì„±(Relevance) í‰ê°€ ì ìˆ˜\")\n",
    "    fluency_eval: str = Field(description=\"ìœ ì°½ì„±(Fluency) í‰ê°€\")\n",
    "    fluency_score: int = Field(description=\"ìœ ì°½ì„±(Fluency) í‰ê°€ ì ìˆ˜\")\n",
    "    completeness_eval: str = Field(description=\"ì™„ì „ì„±(Completeness) í‰ê°€\")\n",
    "    completeness_score: int = Field(description=\"ê´€ë ¨ì„±(Relevance) í‰ê°€ ì ìˆ˜\")\n",
    "\n",
    "class EvaluationResponse(BaseModel):\n",
    "    accuracy: str = Field(description=\"ì •í™•ì„±(Accuracy) í‰ê°€ ê¸°ì¤€\")\n",
    "    relevance: str = Field(description=\"ê´€ë ¨ì„±(Relevance) í‰ê°€ ê¸°ì¤€\")\n",
    "    fluency: str = Field(description=\"ìœ ì°½ì„±(Fluency) í‰ê°€ ê¸°ì¤€\")\n",
    "    completeness: str = Field(description=\"ì™„ì „ì„±(Completeness) í‰ê°€ ê¸°ì¤€\")\n",
    "    evaluation_by_model: List[EvaluationByModel] = Field(description=\"LLM ëª¨ë¸ë³„ ì„¸ë¶€ í‰ê°€ ë‚´ìš©\")\n",
    "    overall: str = Field(description=\"ì¢…í•©í‰ê°€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'EvaluationResponse',\n",
       " 'description': '',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'accuracy': {'description': 'ì •í™•ì„±(Accuracy) í‰ê°€ ê¸°ì¤€',\n",
       "    'type': 'string'},\n",
       "   'relevance': {'description': 'ê´€ë ¨ì„±(Relevance) í‰ê°€ ê¸°ì¤€', 'type': 'string'},\n",
       "   'fluency': {'description': 'ìœ ì°½ì„±(Fluency) í‰ê°€ ê¸°ì¤€', 'type': 'string'},\n",
       "   'completeness': {'description': 'ì™„ì „ì„±(Completeness) í‰ê°€ ê¸°ì¤€',\n",
       "    'type': 'string'},\n",
       "   'evaluation_by_model': {'description': 'LLM ëª¨ë¸ë³„ ì„¸ë¶€ í‰ê°€ ë‚´ìš©',\n",
       "    'type': 'array',\n",
       "    'items': {'type': 'object',\n",
       "     'properties': {'model_id': {'description': 'LLM ëª¨ë¸ ì´ë¦„ ë˜ëŠ” LLM ëª¨ë¸ ID',\n",
       "       'type': 'string'},\n",
       "      'accuracy_eval': {'description': 'ì •í™•ì„±(Accuracy) í‰ê°€', 'type': 'string'},\n",
       "      'accuracy_score': {'description': 'ì •í™•ì„±(Accuracy) í‰ê°€ ì ìˆ˜',\n",
       "       'type': 'integer'},\n",
       "      'relevance_eval': {'description': 'ê´€ë ¨ì„±(Relevance) í‰ê°€', 'type': 'string'},\n",
       "      'relevance_score': {'description': 'ê´€ë ¨ì„±(Relevance) í‰ê°€ ì ìˆ˜',\n",
       "       'type': 'integer'},\n",
       "      'fluency_eval': {'description': 'ìœ ì°½ì„±(Fluency) í‰ê°€', 'type': 'string'},\n",
       "      'fluency_score': {'description': 'ìœ ì°½ì„±(Fluency) í‰ê°€ ì ìˆ˜',\n",
       "       'type': 'integer'},\n",
       "      'completeness_eval': {'description': 'ì™„ì „ì„±(Completeness) í‰ê°€',\n",
       "       'type': 'string'},\n",
       "      'completeness_score': {'description': 'ê´€ë ¨ì„±(Relevance) í‰ê°€ ì ìˆ˜',\n",
       "       'type': 'integer'}},\n",
       "     'required': ['model_id',\n",
       "      'accuracy_eval',\n",
       "      'accuracy_score',\n",
       "      'relevance_eval',\n",
       "      'relevance_score',\n",
       "      'fluency_eval',\n",
       "      'fluency_score',\n",
       "      'completeness_eval',\n",
       "      'completeness_score']}},\n",
       "   'overall': {'description': 'ì¢…í•©í‰ê°€', 'type': 'string'}},\n",
       "  'required': ['accuracy',\n",
       "   'relevance',\n",
       "   'fluency',\n",
       "   'completeness',\n",
       "   'evaluation_by_model',\n",
       "   'overall']}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "f = convert_pydantic_to_openai_function(EvaluationResponse)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "p_parser = PydanticOutputParser(pydantic_object=EvaluationResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    System : \n",
    "    ë„ˆëŠ” llm modelë“¤ì˜ ë‹µë³€ì„ ë¹„êµí•˜ê³  í‰ê°€í•˜ëŠ” AI ì´ë‹¤.\n",
    "    Instructionê³¼ Responses ì•ˆì˜ ê°ê°ì˜ llmë³„ ì‘ë‹µì„ \n",
    "    ì •í™•ì„±(Accuracy), ê´€ë ¨ì„±(Relevance), ìœ ì°½ì„±(Fluency), ì™„ì „ì„±(Completeness) ì¸¡ë©´ì—ì„œ    \n",
    "    ë¶„ì„í•˜ê³  ìµœê³  ì ìˆ˜ 5ì ìœ¼ë¡œ 0ì  ~ 5ì  ì‚¬ì´ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ë¼.\n",
    "\n",
    "    í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜.\n",
    "    Format ì— ë§ì¶°ì„œ ë‹µë³€í•´ì¤˜\n",
    "\n",
    "    Instruction : {instruction}\n",
    "    Responses : {responses}\n",
    "\n",
    "    Format : \n",
    "    {format}\n",
    "    \"\"\",\n",
    "    input_variables=[\"instruction\", \"responses\"],\n",
    "    partial_variables={\"format\" : p_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain_combinded = (\n",
    "    {\"responses\" : chain_llms, \"instruction\" : RunnablePassthrough()}\n",
    "    | eval_prompt \n",
    "    | llm_gpt\n",
    "    | p_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì‹¤í–‰(invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy='ê° ëª¨ë¸ì˜ ì‘ë‹µì´ 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•œ ì‚¬ì‹¤ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ì§€ í‰ê°€' relevance='ê° ëª¨ë¸ì˜ ì‘ë‹µì´ ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€' fluency='ê° ëª¨ë¸ì˜ ì‘ë‹µì´ ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥´ê³  ìì—°ìŠ¤ëŸ¬ìš´ì§€ í‰ê°€' completeness='ê° ëª¨ë¸ì˜ ì‘ë‹µì´ ì§ˆë¬¸ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ì™„ì „í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ì§€ í‰ê°€' evaluation_by_model=[EvaluationByModel(model_id='aya', accuracy_eval=\"ì—¬ëŸ¬ ê³¡ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì–¸ê¸‰í–ˆìœ¼ë‚˜, ì¼ë¶€ ì •ë³´ê°€ ë¶€ì •í™•í•¨ (ì˜ˆ: ìœ ì¬í•˜ì˜ 'ë„¤ë²„ì—”ë”© ìŠ¤í† ë¦¬'ëŠ” 1990ë…„ëŒ€ ê³¡ì´ ì•„ë‹˜)\", accuracy_score=3, relevance_eval='ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ì ì ˆí•˜ë©°, 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì œê³µí•¨', relevance_score=4, fluency_eval='ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë¨', fluency_score=5, completeness_eval='ë‹¤ì–‘í•œ ê³¡ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì–¸ê¸‰í•˜ë©°, 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì˜ íŠ¹ì§•ì„ ì˜ ì„¤ëª…í•¨', completeness_score=4), EvaluationByModel(model_id='llama3:instruct', accuracy_eval='1990ë…„ëŒ€ K-popì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì„¤ëª…í•¨', accuracy_score=5, relevance_eval='ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ì ì ˆí•˜ë©°, 1990ë…„ëŒ€ K-popì˜ ë°œì „ê³¼ ì£¼ìš” ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì˜ ì„¤ëª…í•¨', relevance_score=5, fluency_eval='ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë¨', fluency_score=5, completeness_eval='1990ë…„ëŒ€ K-popì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ í¬ê´„ì ìœ¼ë¡œ ì„¤ëª…í•¨', completeness_score=5), EvaluationByModel(model_id='gemma', accuracy_eval='ì¼ë¶€ ì •ë³´ê°€ ë¶€ì •í™•í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•¨ (ì˜ˆ: SGì›Œë“œ, ì´ë””ì•„, ì¥í˜„ì‹ ë“±ì€ ì˜ ì•Œë ¤ì§€ì§€ ì•Šì€ ì•„í‹°ìŠ¤íŠ¸)', accuracy_score=2, relevance_eval='ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ì ì ˆí•˜ë‚˜, ì¼ë¶€ ì •ë³´ê°€ ë¶€ì •í™•í•¨', relevance_score=3, fluency_eval='ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë¨', fluency_score=5, completeness_eval='1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì˜ ì£¼ìš” íŠ¹ì§•ì„ ì„¤ëª…í•˜ë‚˜, ì–¸ê¸‰ëœ ì•„í‹°ìŠ¤íŠ¸ê°€ ì œí•œì ì„', completeness_score=3), EvaluationByModel(model_id='gpt-4o', accuracy_eval='1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì„¤ëª…í•¨', accuracy_score=5, relevance_eval='ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ì ì ˆí•˜ë©°, 1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì˜ ë°œì „ê³¼ ì£¼ìš” ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì˜ ì„¤ëª…í•¨', relevance_score=5, fluency_eval='ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë¨', fluency_score=5, completeness_eval='1990ë…„ëŒ€ í•œêµ­ ëŒ€ì¤‘ê°€ìš”ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ í¬ê´„ì ìœ¼ë¡œ ì„¤ëª…í•¨', completeness_score=5)] overall='llama3:instructì™€ gpt-4oê°€ ê°€ì¥ ì •í™•í•˜ê³  ì™„ì „í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ayaì™€ gemmaëŠ” ì¼ë¶€ ë¶€ì •í™•í•œ ì •ë³´ê°€ í¬í•¨ë¨'\n"
     ]
    }
   ],
   "source": [
    "response = chain_combinded.invoke({\"instruction\":instruction})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
