{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [실습 환경 Setting]\n",
    "### 1. RealESRGAN 설치\n",
    "- Download RealESRGAN pjt :\n",
    "    ```\n",
    "    pip install basicsr\n",
    "    pip install facexlib\n",
    "    pip install gfpgan\n",
    "    git clone https://github.com/xinntao/Real-ESRGAN.git\n",
    "    <python_home>/Lib/site-packages 위치에 Real-ESRGAN directory 통 copy\n",
    "    cd <python_home>/Lib/site-packages/Real-ESRGAN\n",
    "    pip install -r requirements.txt\n",
    "    python setup.py develop\n",
    "    ```\n",
    "### 2. RealESRGAN 용 AI Model 설치\n",
    "- Download RealESRGAN model(Restoring model):\n",
    "    https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth\n",
    "    \n",
    "    저장 위치 : python code 에 model 위치 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "def upscale_image(input_path, output_path, model_path, scale=2):\n",
    "    # 장치 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=scale)\n",
    "    \n",
    "    # 업스케일러 생성 (half=False로 설정하여 FP32 사용)\n",
    "    upscaler = RealESRGANer(scale=scale, model_path=model_path, model=model, tile=400, tile_pad=10, pre_pad=0, half=False)\n",
    " \n",
    "    # 이미지 로드 (OpenCV 사용)\n",
    "    img = cv2.imread(input_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 변환\n",
    "    \n",
    "    # 업스케일링 수행\n",
    "    output, _ = upscaler.enhance(img, outscale=scale)\n",
    "    \n",
    "    # 결과 저장 (OpenCV 사용)\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)  # RGB에서 BGR로 변환\n",
    "    cv2.imwrite(output_path, output)\n",
    "    \n",
    "    print(f\"업스케일링된 이미지가 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = r'C:\\pypjt\\images\\hugging.jpg'  # 입력 이미지 경로\n",
    "    output_path = \"upscaled_image.png\"  # 출력 이미지 경로\n",
    "    model_path = r\"C:\\pypjt\\restore\\Lib\\site-packages\\Real-ESRGAN\\weights\\RealESRGAN_x4plus.pth\"  # Real-ESRGAN 모델 파일 경로\n",
    "    \n",
    "    upscale_image(input_path, output_path, model_path, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "from insightface.utils import face_align\n",
    "\n",
    "# RealESRGAN을 이용한 업스케일링\n",
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "upsampler = RealESRGANer(\n",
    "    scale=2, model_path='weights/RealESRGAN_x4plus.pth', model=model, tile=400, tile_pad=10, pre_pad=0, half=True\n",
    ")\n",
    "\n",
    "# 이미지 불러오기\n",
    "image = cv2.imread(r'C:\\pypjt\\images\\hugging.jpg')\n",
    "\n",
    "# 리사이즈된 이미지를 업스케일링\n",
    "upscaled_image, _ = upsampler.enhance(image, outscale=2)\n",
    "\n",
    "# 결과 저장\n",
    "cv2.imwrite('upscaled_image.jpg', upscaled_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from basicsr.utils.realesrgan_utils import RealESRGANer\n",
    "from typing import Literal\n",
    "\n",
    "UPSCALE_MODEL_X2 = r\"C:\\models\\RealESRGAN_x2plus.pth\"\n",
    "UPSCALE_MODEL_X4 = r\"C:\\models\\RealESRGAN_x4plus.pth\"\n",
    "\n",
    "def upscale_image(input_image: np.ndarray, scale: Literal[2, 4] = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    이미지를 업스케일링하는 함수.\n",
    "    \n",
    "    :param input_image: ndarray 타입의 입력 이미지\n",
    "    :param model_path: 모델 파일 경로\n",
    "    :param scale: 업스케일 배율 (기본값: 2)\n",
    "    :return: 업스케일링된 ndarray 타입의 이미지\n",
    "    \"\"\"\n",
    "    # 장치 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    # Upscaing Model 선택\n",
    "    model_path = UPSCALE_MODEL_X2 if scale == 2 else UPSCALE_MODEL_X4\n",
    "\n",
    "    # 모델 생성\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=scale)\n",
    "    \n",
    "    # 업스케일러 생성 (half=False로 설정하여 FP32 사용)\n",
    "    upscaler = RealESRGANer(scale=scale, model_path=model_path, model=model, tile=400, tile_pad=10, pre_pad=0, half=False)\n",
    "    \n",
    "    # 입력 이미지가 BGR 형식일 경우, RGB로 변환\n",
    "    if input_image.shape[-1] == 3:  # 이미지가 컬러일 경우\n",
    "        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 업스케일링 수행\n",
    "    output, _ = upscaler.enhance(input_image, outscale=scale)\n",
    "    \n",
    "    # 결과를 BGR로 다시 변환하여 반환\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input = r\"F:\\Windows64\\Studio\\[Urabon]\\asnws-792.+\\gin50.jpg\"\n",
    "# 입력 이미지 로드\n",
    "input_img = cv2.imread(input)\n",
    "\n",
    "# upscaling 함수 호출\n",
    "upscaled_img = upscale_image(input_img, scale=2)\n",
    "\n",
    "# 결과 저장\n",
    "output = r\"F:\\Windows64\\Studio\\[Urabon]\\asnws-792.+\\up_gin50.jpg\"\n",
    "cv2.imwrite(output, upscaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision.transforms.functional import normalize\n",
    "from basicsr.utils import img2tensor, tensor2img\n",
    "from facelib.utils.face_restoration_helper import FaceRestoreHelper\n",
    "from basicsr.utils.registry import ARCH_REGISTRY\n",
    "\n",
    "# 모델 경로 설정\n",
    "CODEFORMER_MODEL = r\"C:\\Users\\tanmi\\stable-diffusion-webui\\models\\Codeformer\\codeformer-v0.1.0.pth\"\n",
    "\n",
    "def restore_face(input_image, use_gpu=False):\n",
    "    \"\"\"\n",
    "    얼굴 복원 함수\n",
    "    \n",
    "    :param input_image: ndarray 타입의 입력 이미지\n",
    "    :param model_path: CodeFormer 모델 파일 경로\n",
    "    :param use_gpu: GPU 사용 여부 (기본값: False)\n",
    "    :return: ndarray 타입의 복원된 이미지\n",
    "    \"\"\"\n",
    "    # 모델 로드\n",
    "    device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "    model = ARCH_REGISTRY.get('CodeFormer')(dim_embd=512, codebook_size=1024, n_head=8, n_layers=9, connect_list=['32', '64', '128', '256']).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(CODEFORMER_MODEL, weights_only=True, map_location=device)['params_ema']\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    # 이미지 크기 저장\n",
    "    h, w, _ = input_image.shape\n",
    "\n",
    "    # 얼굴 검출 및 정렬\n",
    "    face_helper = FaceRestoreHelper(\n",
    "        upscale_factor=1,\n",
    "        face_size=512,\n",
    "        crop_ratio=(1, 1),\n",
    "        det_model='retinaface_resnet50',\n",
    "        save_ext='png',\n",
    "        use_parse=True,\n",
    "        device=device\n",
    "    )\n",
    "    face_helper.read_image(input_image)\n",
    "    face_helper.get_face_landmarks_5(only_center_face=False, resize=640, eye_dist_threshold=5)\n",
    "    face_helper.align_warp_face()\n",
    "\n",
    "    # 얼굴 복원\n",
    "    for idx, cropped_face in enumerate(face_helper.cropped_faces):\n",
    "        cropped_face_t = img2tensor(cropped_face / 255., bgr2rgb=True, float32=True)\n",
    "        normalize(cropped_face_t, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
    "        cropped_face_t = cropped_face_t.unsqueeze(0).to(device)\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output = model(cropped_face_t, w=0.5, adain=True)[0]\n",
    "                restored_face = tensor2img(output, rgb2bgr=True, min_max=(-1, 1))\n",
    "            del output\n",
    "            if use_gpu:\n",
    "                torch.cuda.empty_cache()\n",
    "        except RuntimeError as error:\n",
    "            print(f'Error: {error}')\n",
    "            print('If you encounter CUDA out of memory, try to set --tile with a smaller number.')\n",
    "        else:\n",
    "            restored_face = restored_face.astype('uint8')\n",
    "            face_helper.add_restored_face(restored_face)\n",
    "\n",
    "    # 결과 생성\n",
    "    face_helper.get_inverse_affine(None)\n",
    "    restored_img = face_helper.paste_faces_to_input_image()\n",
    "    \n",
    "    # 최종 이미지 크기 조정 (원본 크기로)\n",
    "    restored_img = cv2.resize(restored_img, (w, h))\n",
    "\n",
    "    return restored_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input = r\"F:\\Windows64\\Studio\\[Urabon]\\asnws-792.+\\up_gin50.jpg\"\n",
    "# 입력 이미지 로드\n",
    "input_img = cv2.imread(input)\n",
    "\n",
    "# upscaling 함수 호출\n",
    "upscaled_img = restore_face(input_img)\n",
    "\n",
    "# 결과 저장\n",
    "output = r\"F:\\Windows64\\Studio\\[Urabon]\\asnws-792.+\\re_up_gin50.jpg\"\n",
    "cv2.imwrite(output, upscaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input = r\"F:\\Windows64\\Studio\\[Urabon]\\asnws-792.+\\gin49.jpg\"\n",
    "# 입력 이미지 로드\n",
    "input_img = cv2.imread(input)\n",
    "\n",
    "# upscaling 함수 호출\n",
    "upscaled_img = upscale_image(input_img, scale=2)\n",
    "# restoring 함수 호출\n",
    "restored_img = restore_face(upscaled_img)\n",
    "\n",
    "# 결과 저장\n",
    "output = r\"F:\\Windows64\\Studio\\[Urabon]\\asnws-792.+\\re_up_gin49.jpg\"\n",
    "cv2.imwrite(output, restored_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 입력 디렉토리와 출력 디렉토리\n",
    "input_dir = r\"F:\\[Fake]\\[facing]\\multi\"\n",
    "output_dir = r\"F:\\[Fake]\\[facing]\\multi\\restored\"\n",
    "\n",
    "# 출력 디렉토리가 없으면 생성\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 디렉토리 내의 모든 파일 처리\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith((\".jpg\", \".jpeg\", \".png\")):  # 이미지 파일 확장자 체크\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # 입력 이미지 로드\n",
    "        input_img = cv2.imread(input_path)\n",
    "\n",
    "        if input_img is not None:  # 이미지가 정상적으로 로드되었는지 확인\n",
    "            # upscaling 함수 호출\n",
    "            upscaled_img = upscale_image(input_img, scale=2)\n",
    "\n",
    "            # restoring 함수 호출\n",
    "            restored_img = restore_face(upscaled_img)\n",
    "\n",
    "            # 결과 저장\n",
    "            output_path = os.path.join(output_dir, f\"re_up_{filename}\")\n",
    "            cv2.imwrite(output_path, restored_img)\n",
    "            print(f\"Processed and saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to load: {input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 입력 디렉토리와 출력 디렉토리\n",
    "input_dir = r\"F:\\[Fake]\\[facing]\\multi\"\n",
    "output_dir = r\"F:\\[Fake]\\[facing]\\multi\\restored\"\n",
    "\n",
    "# 출력 디렉토리가 없으면 생성\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 디렉토리 내의 모든 파일 처리\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith((\".jpg\", \".jpeg\", \".png\")):  # 이미지 파일 확장자 체크\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # 입력 이미지 로드\n",
    "        input_img = cv2.imread(input_path)\n",
    "\n",
    "        if input_img is not None:  # 이미지가 정상적으로 로드되었는지 확인\n",
    "            \n",
    "            # restoring 함수 호출\n",
    "            restored_img = restore_face(input_img)\n",
    "\n",
    "            # 결과 저장\n",
    "            output_path = os.path.join(output_dir, f\"re_up_{filename}\")\n",
    "            cv2.imwrite(output_path, restored_img)\n",
    "            print(f\"Processed and saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to load: {input_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
