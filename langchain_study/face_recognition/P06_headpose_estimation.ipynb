{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAW PITCH ROLL\n",
    "\n",
    "![Link](./images/yaw_pitch_roll.jpg)\n",
    "\n",
    "- 주의 : Pitch의 절대값이 커질수로 Roll 값의 신뢰도는 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app.common import Face\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def get_yaw_pitch_roll(face: Face) -> Tuple[Optional[float], Optional[float], Optional[float]]:\n",
    "    return face.pose[1], face.pose[0], face.pose[2] #yaw, pitch, roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_IMG_FILE = \"cross.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 인식을 위해 InsightFace를 사용하는 샘플 코드\n",
    "\n",
    "import cv2\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# FaceAnalysis 객체 초기화 (사전 학습된 모델 사용)\n",
    "app = FaceAnalysis(name='buffalo_l')  # 'buffalo_l'는 사전 학습된 모델 이름입니다.\n",
    "app.prepare(ctx_id=-1)  # ctx_id=0은 GPU 사용, ctx_id=-1은 CPU 사용\n",
    "\n",
    "# NMS 임계값 설정\n",
    "# - 낮출수록 더 많은 얼굴이 검출될 수 있지만 오탐률이 증가할 수 있음\n",
    "app.det_model.nms_thresh = 0.6\n",
    "\n",
    "# 이미지 파일 읽기\n",
    "#img = cv2.imread(\"./faces/group_image.jpg\")  # 처리할 이미지 파일의 경로로 변경하세요.\n",
    "#img = cv2.imread(\"full-face-view.png\")\n",
    "#img = cv2.imread(\"F1.large.jpg\")\n",
    "img = cv2.imread(TARGET_IMG_FILE)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"이미지를 불러올 수 없습니다. 경로를 확인하세요\")\n",
    "\n",
    "# 얼굴 검출 및 임베딩 추출\n",
    "faces = app.get(img)\n",
    "\n",
    "# 검출된 얼굴 처리\n",
    "for idx, face in enumerate(faces):\n",
    "    \n",
    "    # 얼굴 영역 표시\n",
    "    bbox = face.bbox.astype(int)\n",
    "    #cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "    # 얼굴 임베딩 출력\n",
    "    #print(f\"얼굴 {idx+1} 임베딩 벡터:\\n{face.embedding}\")\n",
    "\n",
    "    # YAW, PITCH, ROLL 계산\n",
    "    yaw, pitch, roll = get_yaw_pitch_roll(face)\n",
    "\n",
    "    # YAW, PITCH, ROLL 값 표시\n",
    "    if yaw is not None and pitch is not None and roll is not None:\n",
    "        cv2.putText(img, f\"YAW: {yaw:.1f}\", (bbox[0] + 5, bbox[1] + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (127, 127, 127), 1)\n",
    "        cv2.putText(img, f\"PITCH: {pitch:.1f}\", (bbox[0] + 5, bbox[1] + 35), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (127, 127, 127), 1)\n",
    "        cv2.putText(img, f\"ROLL: {roll:.1f}\", (bbox[0] + 5, bbox[1] + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (127, 127, 127), 1)\n",
    "\n",
    "# 결과 이미지 표시\n",
    "cv2.imshow('Detection Result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import FaceSwapper, restore_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 얼굴 모두 Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (320, 320)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "inswapper-shape: [1, 3, 128, 128]\n",
      "소스 얼굴이 설정되었습니다. 인덱스: 0\n",
      "faces count : 16\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_swapper = FaceSwapper(det_size=(640, 640), nms_thresh=0.3)\n",
    "\n",
    "# 소스 얼굴 이미지 로드\n",
    "source_img = cv2.imread(\"./faces/old_man.jpg\")\n",
    "    \n",
    "# 소스 얼굴 설정 (face_index는 선택 사항)\n",
    "success = face_swapper.set_source_face(source_img, face_index=0)\n",
    "if not success:\n",
    "    print(\"소스 얼굴 설정에 실패했습니다.\")\n",
    "    raise StopIteration  # 셀 실행을 중단\n",
    "    \n",
    "# 대상 이미지 로드\n",
    "target_img = cv2.imread(TARGET_IMG_FILE)\n",
    "    \n",
    "# 얼굴 교체 수행 (ndarray 이미지를 입력으로 받아 결과를 ndarray로 반환)\n",
    "swapped_img = face_swapper.swap_faces_in_image(target_img, draw_rectangle=True)\n",
    "\n",
    "if swapped_img is not None:\n",
    "    # 결과 이미지 표시\n",
    "    cv2.imshow('Result', swapped_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()    \n",
    "else:\n",
    "    print(\"얼굴 교체에 실패했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 얼굴 모두 Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pypjt\\face\\Lib\\site-packages\\codeformer\\facelib\\detection\\__init__.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  load_net = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
      "c:\\pypjt\\face\\Lib\\site-packages\\codeformer\\facelib\\parsing\\__init__.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  load_net = torch.load(model_path, map_location=lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 대상 이미지 로드\n",
    "target_img = cv2.imread(TARGET_IMG_FILE)\n",
    "    \n",
    "# 얼굴 교체 수행 (ndarray 이미지를 입력으로 받아 결과를 ndarray로 반환)\n",
    "swapped_img = restore_face(target_img, draw_rectangle=True)\n",
    "\n",
    "if swapped_img is not None:\n",
    "    # 결과 이미지 표시\n",
    "    cv2.imshow('Result', swapped_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()    \n",
    "else:\n",
    "    print(\"얼굴 복구에 실패했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
