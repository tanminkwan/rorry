{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=ek05M8eCk7M\n",
      "[youtube] ek05M8eCk7M: Downloading webpage\n",
      "[youtube] ek05M8eCk7M: Downloading ios player API JSON\n",
      "[youtube] ek05M8eCk7M: Downloading player e38bb6de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] ek05M8eCk7M: nsig extraction failed: Some formats may be missing\n",
      "         n = jrX2HCYBWf_MoznJ ; player = https://www.youtube.com/s/player/e38bb6de/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] ek05M8eCk7M: nsig extraction failed: Some formats may be missing\n",
      "         n = fMwAfFGhnG5jzmuK ; player = https://www.youtube.com/s/player/e38bb6de/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] ek05M8eCk7M: Downloading m3u8 information\n",
      "[info] ek05M8eCk7M: Downloading 1 format(s): 625+140\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 50\n",
      "[download] Destination: Hanni_ek05M8eCk7M.f625.mp4\n",
      "[download] 100% of  551.14MiB in 00:00:50 at 11.00MiB/s                \n",
      "[download] Destination: Hanni_ek05M8eCk7M.f140.m4a\n",
      "[download] 100% of    4.29MiB in 00:00:00 at 12.40MiB/s  \n",
      "[Merger] Merging formats into \"Hanni_ek05M8eCk7M.mp4\"\n",
      "Deleting original file Hanni_ek05M8eCk7M.f625.mp4 (pass -k to keep)\n",
      "Deleting original file Hanni_ek05M8eCk7M.f140.m4a (pass -k to keep)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hanni_ek05M8eCk7M.mp4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions import download_youtube\n",
    "video_id = 'ek05M8eCk7M'\n",
    "#video_id = 'I-cxigjLG0I'\n",
    "youtube_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "job_id = 'Hanni'\n",
    "file_path, file_name =  download_youtube(youtube_url, job_id=job_id)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 14:22:39,872 - INFO - Successfully created segment: hanni.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_name': 'hanni.mp4',\n",
       "  'start': 0,\n",
       "  'duration': 240,\n",
       "  'success': True,\n",
       "  'error': None}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions import slice_video\n",
    "slice_video(file_name, [(0, 240, 'hanni.mp4')], height=540, width=960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = \"../face_recognition/test_hanni2.jpg\"\n",
    "#target_video = \"hanni.mp4\"\n",
    "target_video = \"삼성SDS_FabriX.mp4\"\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# 특정 인물의 이미지를 로드하여 인코딩\n",
    "known_image = face_recognition.load_image_file(base_image)\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# 비디오 파일 로드\n",
    "video_capture = cv2.VideoCapture(target_video)\n",
    "\n",
    "# 변수 초기화\n",
    "trackers = []\n",
    "face_names = []\n",
    "face_distances = []\n",
    "frame_skip = 12\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # 비디오에서 한 프레임씩 읽기\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # 추적기와 얼굴 정보 초기화\n",
    "        trackers = []\n",
    "        face_names = []\n",
    "        face_distances = []\n",
    "\n",
    "        # 얼굴 위치와 인코딩 탐지\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for face_location, face_encoding in zip(face_locations, face_encodings):\n",
    "            top, right, bottom, left = face_location\n",
    "\n",
    "            # 얼굴 거리 계산\n",
    "            distance = face_recognition.face_distance([known_face_encoding], face_encoding)[0]\n",
    "\n",
    "            # 임계값 설정 (예: 0.6)\n",
    "            tolerance = 0.46\n",
    "\n",
    "            if distance < tolerance:\n",
    "                name = \"Specific Person\"\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # 추적기 초기화\n",
    "            tracker = cv2.legacy.TrackerKCF_create()\n",
    "            bbox = (left, top, right - left, bottom - top)\n",
    "            tracker.init(frame, bbox)\n",
    "            trackers.append(tracker)\n",
    "            face_names.append(name)\n",
    "            face_distances.append(distance)\n",
    "    else:\n",
    "        # 모든 추적기 업데이트\n",
    "        new_trackers = []\n",
    "        new_face_names = []\n",
    "        new_face_distances = []\n",
    "\n",
    "        for tracker, name, distance in zip(trackers, face_names, face_distances):\n",
    "            success, bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                new_trackers.append(tracker)\n",
    "                new_face_names.append(name)\n",
    "                new_face_distances.append(distance)\n",
    "                left, top, width, height = [int(v) for v in bbox]\n",
    "                right = left + width\n",
    "                bottom = top + height\n",
    "\n",
    "                # 사각형과 텍스트 표시\n",
    "                if name == \"Specific Person\":\n",
    "                    # 특정 인물에 대해 빨간색 사각형과 이름 및 거리 표시\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                    # 이름 표시\n",
    "                    cv2.putText(frame, name, (left, bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                    # 거리 표시 (이름 아래)\n",
    "                    cv2.putText(frame, f\"Distance: {distance:.2f}\", (left, bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    # 다른 인물에 대해 초록색 사각형과 이름만 표시\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, name, (left, bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                    # 거리 표시 (이름 아래)\n",
    "                    cv2.putText(frame, f\"Distance: {distance:.2f}\", (left, bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # 추적기와 얼굴 정보 업데이트\n",
    "        trackers = new_trackers\n",
    "        face_names = new_face_names\n",
    "        face_distances = new_face_distances\n",
    "\n",
    "    # 비디오 출력\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 모든 작업 완료 후 클린업\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file = \"../face_recognition/faces/newjeans01_g.jpg\"\n",
    "known_file = \"../face_recognition/test_hanni2.jpg\"\n",
    "target_file = \"../face_recognition/test_yun.jpg\"\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 소스 이미지 로드 (얼굴을 교체할 이미지)\n",
    "source_image = face_recognition.load_image_file(source_file)\n",
    "source_image_rgb = source_image[:, :, ::-1]\n",
    "\n",
    "# 대상 얼굴 이미지 로드 (교체할 얼굴)\n",
    "target_face_image = face_recognition.load_image_file(target_file)\n",
    "target_face_locations = face_recognition.face_locations(target_face_image)\n",
    "if len(target_face_locations) == 0:\n",
    "    print(\"대상 얼굴 이미지에서 얼굴을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 대상 얼굴의 첫 번째 얼굴 선택\n",
    "target_face_location = target_face_locations[0]\n",
    "top_t, right_t, bottom_t, left_t = target_face_location\n",
    "target_face = target_face_image[top_t:bottom_t, left_t:right_t]\n",
    "\n",
    "# 교체할 얼굴 로드 (소스 이미지에서 교체하려는 특정 얼굴)\n",
    "known_face_image = face_recognition.load_image_file(known_file)\n",
    "known_face_encodings = face_recognition.face_encodings(known_face_image)\n",
    "if len(known_face_encodings) == 0:\n",
    "    print(\"교체할 얼굴 이미지에서 얼굴을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "known_face_encoding = known_face_encodings[0]\n",
    "\n",
    "# 소스 이미지에서 모든 얼굴과 인코딩 찾기\n",
    "source_face_locations = face_recognition.face_locations(source_image)\n",
    "source_face_encodings = face_recognition.face_encodings(source_image, source_face_locations)\n",
    "\n",
    "# 소스 이미지의 각 얼굴에 대해 반복\n",
    "for (face_location, face_encoding) in zip(source_face_locations, source_face_encodings):\n",
    "    # 이 얼굴이 교체하려는 얼굴인지 확인\n",
    "    matches = face_recognition.compare_faces([known_face_encoding], face_encoding, tolerance=0.4)\n",
    "\n",
    "    if matches[0]:\n",
    "        # 교체할 얼굴을 찾았습니다.\n",
    "        top, right, bottom, left = face_location\n",
    "        # 대상 얼굴을 교체할 얼굴의 크기에 맞게 조정\n",
    "        face_width = right - left\n",
    "        face_height = bottom - top\n",
    "        target_face_resized = cv2.resize(target_face, (face_width, face_height))\n",
    "\n",
    "        # 소스 이미지에서 얼굴 교체\n",
    "        source_image[top:bottom, left:right] = target_face_resized\n",
    "\n",
    "# 결과 저장\n",
    "cv2.imwrite(\"result.jpg\", cv2.cvtColor(source_image, cv2.COLOR_RGB2BGR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
