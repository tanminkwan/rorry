{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import download_youtube\n",
    "video_id = 'ek05M8eCk7M'\n",
    "#video_id = 'I-cxigjLG0I'\n",
    "youtube_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "job_id = 'Hanni'\n",
    "file_path, file_name =  download_youtube(youtube_url, job_id=job_id)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import slice_video\n",
    "slice_video(file_name, [(0, 240, 'hanni.mp4')], height=540, width=960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV 설치\n",
    "- `pip uninstall opencv-python`\n",
    "- `pip install opencv-contrib-python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection & Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = \"../face_recognition/test_hanni2.jpg\"\n",
    "target_video = \"hanni.mp4\"\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# 특정 인물의 이미지를 로드하여 인코딩\n",
    "known_image = face_recognition.load_image_file(base_image)\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# 비디오 파일 로드\n",
    "video_capture = cv2.VideoCapture(target_video)\n",
    "\n",
    "# 변수 초기화\n",
    "trackers = []\n",
    "face_names = []\n",
    "face_distances = []\n",
    "frame_skip = 12\n",
    "frame_count = 0\n",
    "\n",
    "def expand_bounding_box(left, top, width, height, frame_width, frame_height, expand_ratio=0.25):\n",
    "    expand_width = int(width * expand_ratio)\n",
    "    expand_height = int(height * expand_ratio)\n",
    "    \n",
    "    expanded_left = int(max(0, left - expand_width))\n",
    "    expanded_top = int(max(0, top - expand_height))\n",
    "    expanded_right = int(min(frame_width, left + width + expand_width))\n",
    "    expanded_bottom = int(min(frame_height, top + height + expand_height))\n",
    "    \n",
    "    return expanded_left, expanded_top, expanded_right, expanded_bottom\n",
    "\n",
    "def draw_face_annotations(frame, name, distance, bbox, frame_width, frame_height):\n",
    "    left, top, width, height = bbox\n",
    "    expanded_left, expanded_top, expanded_right, expanded_bottom = expand_bounding_box(\n",
    "        left, top, width, height, frame_width, frame_height)\n",
    "    \n",
    "    # 좌표 값을 정수형으로 변환\n",
    "    expanded_left = int(expanded_left)\n",
    "    expanded_top = int(expanded_top)\n",
    "    expanded_right = int(expanded_right)\n",
    "    expanded_bottom = int(expanded_bottom)\n",
    "    \n",
    "    # 이름에 따른 색상 설정\n",
    "    if name == \"Specific Person\":\n",
    "        color = (0, 0, 255)  # 빨간색\n",
    "    elif name == \"Candidate\":\n",
    "        color = (255, 0, 0)  # 파란색\n",
    "    else:\n",
    "        color = (0, 255, 0)  # 초록색\n",
    "    \n",
    "    # 사각형 그리기\n",
    "    cv2.rectangle(frame, (expanded_left, expanded_top), (expanded_right, expanded_bottom), color, 2)\n",
    "    \n",
    "    # 이름과 거리 표시\n",
    "    cv2.putText(frame, name, (expanded_left, expanded_bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    cv2.putText(frame, f\"Distance: {distance:.2f}\", (expanded_left, expanded_bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "while True:\n",
    "    # 비디오에서 한 프레임씩 읽기\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 프레임의 높이와 너비를 가져오기\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # 추적기와 얼굴 정보 초기화\n",
    "        trackers = []\n",
    "        face_names = []\n",
    "        face_distances = []\n",
    "\n",
    "        # 얼굴 위치와 인코딩 탐지\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        distances = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 얼굴 거리 계산\n",
    "            distance = face_recognition.face_distance([known_face_encoding], face_encoding)[0]\n",
    "            distances.append(distance)\n",
    "\n",
    "        # 임계값 설정 (예: 0.46)\n",
    "        tolerance = 0.46\n",
    "\n",
    "        # 거리 기준으로 가장 작은 인덱스 찾기\n",
    "        specific_person_index = None\n",
    "        if len(distances) > 0:\n",
    "            min_distance = min(distances)\n",
    "            if min_distance < tolerance:\n",
    "                specific_person_index = distances.index(min_distance)\n",
    "\n",
    "        for idx, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):\n",
    "            top, right, bottom, left = face_location\n",
    "\n",
    "            # 얼굴 거리 계산\n",
    "            distance = distances[idx]\n",
    "\n",
    "            if distance < tolerance:\n",
    "                if idx == specific_person_index:\n",
    "                    name = \"Specific Person\"\n",
    "                else:\n",
    "                    name = \"Candidate\"\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # 추적기 초기화\n",
    "            tracker = cv2.legacy.TrackerKCF_create()\n",
    "            bbox = (left, top, right - left, bottom - top)\n",
    "            tracker.init(frame, bbox)\n",
    "            trackers.append(tracker)\n",
    "            face_names.append(name)\n",
    "            face_distances.append(distance)\n",
    "\n",
    "            # 얼굴 주석 그리기\n",
    "            draw_face_annotations(frame, name, distance, bbox, frame_width, frame_height)\n",
    "\n",
    "    else:\n",
    "        # 모든 추적기 업데이트\n",
    "        new_trackers = []\n",
    "        new_face_names = []\n",
    "        new_face_distances = []\n",
    "\n",
    "        for tracker, name, distance in zip(trackers, face_names, face_distances):\n",
    "            success, bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                new_trackers.append(tracker)\n",
    "                new_face_names.append(name)\n",
    "                new_face_distances.append(distance)\n",
    "\n",
    "                # 좌표 값을 정수형으로 변환\n",
    "                bbox = tuple(map(int, bbox))\n",
    "\n",
    "                # 얼굴 주석 그리기\n",
    "                draw_face_annotations(frame, name, distance, bbox, frame_width, frame_height)\n",
    "\n",
    "        # 추적기와 얼굴 정보 업데이트\n",
    "        trackers = new_trackers\n",
    "        face_names = new_face_names\n",
    "        face_distances = new_face_distances\n",
    "\n",
    "    # 비디오 출력\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 모든 작업 완료 후 클린업\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Web UI API 를 사용하여 Face Swapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = \"../face_recognition/test_hanni2.jpg\"\n",
    "source_image = \"../face_recognition/faces/김태희.jpg\"\n",
    "target_video = \"hanni.mp4\"\n",
    "\n",
    "import io\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from get_swapped_face import get_swapped_face\n",
    "\n",
    "# 특정 인물의 이미지를 로드하여 인코딩\n",
    "known_image = face_recognition.load_image_file(base_image)\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "with open(source_image, \"rb\") as source_file:\n",
    "    source_bytes = source_file.read()\n",
    "\n",
    "# 비디오 파일 로드\n",
    "video_capture = cv2.VideoCapture(target_video)\n",
    "\n",
    "# 변수 초기화\n",
    "trackers = []\n",
    "face_names = []\n",
    "face_distances = []\n",
    "frame_skip = 12\n",
    "frame_count = 0\n",
    "\n",
    "# swap_face 함수가 이미 존재한다고 가정합니다.\n",
    "# def swap_face(jpg_binary):\n",
    "#     # 얼굴 스왑 처리 후 동일한 크기의 jpg_binary 반환\n",
    "#     return swapped_jpg_binary\n",
    "\n",
    "while True:\n",
    "    # 비디오에서 한 프레임씩 읽기\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 프레임의 높이와 너비를 가져오기\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # 추적기와 얼굴 정보 초기화\n",
    "        trackers = []\n",
    "        face_names = []\n",
    "        face_distances = []\n",
    "\n",
    "        # 얼굴 위치와 인코딩 탐지\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        distances = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 얼굴 거리 계산\n",
    "            distance = face_recognition.face_distance([known_face_encoding], face_encoding)[0]\n",
    "            distances.append(distance)\n",
    "\n",
    "        # 임계값 설정 (예: 0.46)\n",
    "        tolerance = 0.46\n",
    "\n",
    "        # 거리 기준으로 가장 작은 인덱스 찾기\n",
    "        specific_person_index = None\n",
    "        if len(distances) > 0:\n",
    "            min_distance = min(distances)\n",
    "            if min_distance < tolerance:\n",
    "                specific_person_index = distances.index(min_distance)\n",
    "\n",
    "        for idx, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):\n",
    "            top, right, bottom, left = face_location\n",
    "\n",
    "            # 얼굴 거리 계산\n",
    "            distance = distances[idx]\n",
    "\n",
    "            if distance < tolerance:\n",
    "                if idx == specific_person_index:\n",
    "                    name = \"Specific Person\"\n",
    "                else:\n",
    "                    name = \"Candidate\"\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # 추적기 초기화\n",
    "            tracker = cv2.legacy.TrackerKCF_create()\n",
    "            bbox = (left, top, right - left, bottom - top)\n",
    "            tracker.init(frame, bbox)\n",
    "            trackers.append(tracker)\n",
    "            face_names.append(name)\n",
    "            face_distances.append(distance)\n",
    "    else:\n",
    "        # 모든 추적기 업데이트\n",
    "        new_trackers = []\n",
    "        new_face_names = []\n",
    "        new_face_distances = []\n",
    "\n",
    "        for tracker, name, distance in zip(trackers, face_names, face_distances):\n",
    "            success, bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                new_trackers.append(tracker)\n",
    "                new_face_names.append(name)\n",
    "                new_face_distances.append(distance)\n",
    "                left, top, width, height = [int(v) for v in bbox]\n",
    "                right = left + width\n",
    "                bottom = top + height\n",
    "\n",
    "                # 사각형을 4방으로 1.5배 확장\n",
    "                expand_width = int(width * 0.25)  # 원래의 0.25배씩 좌우로 확장\n",
    "                expand_height = int(height * 0.25)  # 원래의 0.25배씩 상하로 확장\n",
    "\n",
    "                # 새로운 좌표 계산 (프레임 경계를 넘지 않도록 조정)\n",
    "                expanded_left = max(0, left - expand_width)\n",
    "                expanded_top = max(0, top - expand_height)\n",
    "                expanded_right = min(frame_width, right + expand_width)\n",
    "                expanded_bottom = min(frame_height, bottom + expand_height)\n",
    "\n",
    "                # 사각형과 텍스트 표시\n",
    "                if name == \"Specific Person\":\n",
    "                    # 특정 인물에 대해 얼굴 스왑 처리\n",
    "\n",
    "                    # 확장된 사각형 영역 추출\n",
    "                    face_region = frame[expanded_top:expanded_bottom, expanded_left:expanded_right]\n",
    "\n",
    "                    # 이미지를 JPG 바이너리로 인코딩\n",
    "                    success_enc, jpg_buffer = cv2.imencode('.jpg', face_region)\n",
    "                    if success_enc:\n",
    "                        jpg_binary = jpg_buffer.tobytes()\n",
    "\n",
    "                        # swap_face 함수 호출\n",
    "                        swap_png_binary = get_swapped_face(source_bytes, jpg_binary)\n",
    "\n",
    "                        # swap_png_binary가 BytesIO 객체인 경우 처리\n",
    "                        if isinstance(swap_png_binary, io.BytesIO):\n",
    "                            swap_png_binary = swap_png_binary.getvalue()\n",
    "\n",
    "                        # swap_png_binary를 이미지로 디코딩\n",
    "                        swap_image_array = np.frombuffer(swap_png_binary, np.uint8)\n",
    "                        swap_image = cv2.imdecode(swap_image_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "                        # 스왑된 이미지의 크기가 영역과 다를 수 있으므로 리사이즈\n",
    "                        swap_image = cv2.resize(swap_image, (expanded_right - expanded_left, expanded_bottom - expanded_top))\n",
    "\n",
    "                        # 스왑된 이미지를 프레임에 적용\n",
    "                        frame[expanded_top:expanded_bottom, expanded_left:expanded_right] = swap_image\n",
    "\n",
    "                    # 사각형 그리기\n",
    "                    color = (0, 0, 255)  # 빨간색\n",
    "                    cv2.rectangle(frame, (expanded_left, expanded_top), (expanded_right, expanded_bottom), color, 2)\n",
    "                    # 이름 표시\n",
    "                    cv2.putText(frame, name, (expanded_left, expanded_bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    # 거리 표시 (이름 아래)\n",
    "                    cv2.putText(frame, f\"Distance: {distance:.2f}\", (expanded_left, expanded_bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "                elif name == \"Candidate\":\n",
    "                    # 후보자는 파란색 사각형과 이름 표시\n",
    "                    color = (255, 0, 0)\n",
    "                    cv2.rectangle(frame, (expanded_left, expanded_top), (expanded_right, expanded_bottom), color, 2)\n",
    "                    cv2.putText(frame, name, (expanded_left, expanded_bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    cv2.putText(frame, f\"Distance: {distance:.2f}\", (expanded_left, expanded_bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                else:\n",
    "                    # 다른 인물에 대해 초록색 사각형과 이름만 표시\n",
    "                    color = (0, 255, 0)\n",
    "                    cv2.rectangle(frame, (expanded_left, expanded_top), (expanded_right, expanded_bottom), color, 2)\n",
    "                    cv2.putText(frame, name, (expanded_left, expanded_bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    cv2.putText(frame, f\"Distance: {distance:.2f}\", (expanded_left, expanded_bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # 추적기와 얼굴 정보 업데이트\n",
    "        trackers = new_trackers\n",
    "        face_names = new_face_names\n",
    "        face_distances = new_face_distances\n",
    "\n",
    "    # 비디오 출력\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 모든 작업 완료 후 클린업\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insightface library 를 사용하여 Face Swapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    pip install insightface\n",
    "    pip install onnxruntime #for CPU-only\n",
    "    pip install onnxruntime-gpu #For GPU\n",
    "    pip uninstall opencv-python-headless\n",
    "    pip install opencv-contrib-python-headless # 또는 opencv-contrib-python\n",
    "```\n",
    "- Download `inswapper_128.onnx` & Locate it in a specific directory\n",
    "- buffalo_l download from : \n",
    "    https://github.com/deepinsight/insightface/releases\n",
    "\n",
    "- unzip buffalo_l.zip on `C:\\Users\\<user>\\.insightface\\models\\buffalo_l`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from inswapper import FaceSwapper\n",
    "\n",
    "base_image = \"../face_recognition/test_hanni2.jpg\"\n",
    "source_image = \"../face_recognition/faces/yunsy.jpg\"\n",
    "target_video = \"hanni.mp4\"\n",
    "\n",
    "# 특정 인물의 이미지를 로드하여 인코딩\n",
    "known_image = face_recognition.load_image_file(base_image)\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# FaceSwapper 클래스 인스턴스 생성\n",
    "face_swapper = FaceSwapper(det_size=(160, 160))\n",
    "\n",
    "# 소스 얼굴 설정 (face_index는 선택 사항)\n",
    "success = face_swapper.set_source_face(source_image)\n",
    "\n",
    "if not success:\n",
    "    print(\"소스 얼굴 설정에 실패했습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 비디오 파일 로드\n",
    "video_capture = cv2.VideoCapture(target_video)\n",
    "\n",
    "# 변수 초기화\n",
    "trackers = []\n",
    "face_names = []\n",
    "face_distances = []\n",
    "frame_skip = 12\n",
    "frame_count = 0\n",
    "\n",
    "def process_face(frame, name, distance, bbox, frame_width, frame_height):\n",
    "    left, top, width, height = bbox\n",
    "    expand_ratio=0.3\n",
    "    expand_width = int(width * expand_ratio)\n",
    "    expand_height = int(height * expand_ratio)\n",
    "\n",
    "    expanded_left = int(max(0, left - expand_width))\n",
    "    expanded_top = int(max(0, top - expand_height))\n",
    "    expanded_right = int(min(frame_width, left + width + expand_width))\n",
    "    expanded_bottom = int(min(frame_height, top + height + expand_height))\n",
    "\n",
    "    # 얼굴 영역 추출\n",
    "    face_region = frame[expanded_top:expanded_bottom, expanded_left:expanded_right]\n",
    "\n",
    "    if name == \"Specific Person\":\n",
    "        # 얼굴 스왑 처리\n",
    "        swap_image = face_swapper.swap_faces_in_image(face_region)\n",
    "        if swap_image is not None:\n",
    "            # 스왑된 이미지를 얼굴 영역 크기에 맞게 조정\n",
    "            swap_image = cv2.resize(swap_image, (expanded_right - expanded_left, expanded_bottom - expanded_top))\n",
    "            # 스왑된 얼굴을 프레임에 적용\n",
    "            frame[expanded_top:expanded_bottom, expanded_left:expanded_right] = swap_image\n",
    "        color = (0, 0, 255)  # 빨간색\n",
    "    elif name == \"Candidate\":\n",
    "        color = (255, 0, 0)  # 파란색\n",
    "    else:\n",
    "        color = (0, 255, 0)  # 초록색\n",
    "\n",
    "    # 사각형 그리기\n",
    "    cv2.rectangle(frame, (expanded_left, expanded_top), (expanded_right, expanded_bottom), color, 2)\n",
    "    # 이름과 거리 표시\n",
    "    cv2.putText(frame, name, (expanded_left, expanded_bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    cv2.putText(frame, f\"Distance: {distance:.2f}\", (expanded_left, expanded_bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "while True:\n",
    "    # 비디오에서 한 프레임씩 읽기\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 프레임의 높이와 너비를 가져오기\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # 추적기와 얼굴 정보 초기화\n",
    "        trackers = []\n",
    "        face_names = []\n",
    "        face_distances = []\n",
    "\n",
    "        # 얼굴 위치와 인코딩 탐지\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        distances = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 얼굴 거리 계산\n",
    "            distance = face_recognition.face_distance([known_face_encoding], face_encoding)[0]\n",
    "            distances.append(distance)\n",
    "\n",
    "        # 임계값 설정 (예: 0.46)\n",
    "        tolerance = 0.46\n",
    "\n",
    "        # 거리 기준으로 가장 작은 인덱스 찾기\n",
    "        specific_person_index = None\n",
    "        if len(distances) > 0:\n",
    "            min_distance = min(distances)\n",
    "            if min_distance < tolerance:\n",
    "                specific_person_index = distances.index(min_distance)\n",
    "\n",
    "        for idx, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):\n",
    "            top, right, bottom, left = face_location\n",
    "            width = right - left\n",
    "            height = bottom - top\n",
    "            bbox = (left, top, width, height)\n",
    "\n",
    "            # 얼굴 거리 계산\n",
    "            distance = distances[idx]\n",
    "\n",
    "            if distance < tolerance:\n",
    "                if idx == specific_person_index:\n",
    "                    name = \"Specific Person\"\n",
    "                else:\n",
    "                    name = \"Candidate\"\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # 추적기 초기화\n",
    "            tracker = cv2.legacy.TrackerKCF_create()\n",
    "            tracker.init(frame, bbox)\n",
    "            trackers.append(tracker)\n",
    "            face_names.append(name)\n",
    "            face_distances.append(distance)\n",
    "\n",
    "            # 얼굴 처리 및 주석 그리기\n",
    "            process_face(frame, name, distance, bbox, frame_width, frame_height)\n",
    "\n",
    "    else:\n",
    "        # 모든 추적기 업데이트\n",
    "        new_trackers = []\n",
    "        new_face_names = []\n",
    "        new_face_distances = []\n",
    "\n",
    "        for tracker, name, distance in zip(trackers, face_names, face_distances):\n",
    "            success, bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                bbox = tuple(map(int, bbox))\n",
    "                new_trackers.append(tracker)\n",
    "                new_face_names.append(name)\n",
    "                new_face_distances.append(distance)\n",
    "\n",
    "                # 얼굴 처리 및 주석 그리기\n",
    "                process_face(frame, name, distance, bbox, frame_width, frame_height)\n",
    "\n",
    "        # 추적기와 얼굴 정보 업데이트\n",
    "        trackers = new_trackers\n",
    "        face_names = new_face_names\n",
    "        face_distances = new_face_distances\n",
    "\n",
    "    # 비디오 출력\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 모든 작업 완료 후 클린업\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prof\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\prof\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\tiffanie.kim/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (160, 160)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "inswapper-shape: [1, 3, 128, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prof\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 얼굴이 설정되었습니다. 인덱스: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 174\u001b[0m\n\u001b[0;32m    171\u001b[0m     video_capture\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    172\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m--> 174\u001b[0m \u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 139\u001b[0m, in \u001b[0;36mview\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m         face_distances\u001b[38;5;241m.\u001b[39mappend(distance)\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;66;03m# 얼굴 처리 및 주석 그리기\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m         \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_face\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# 모든 추적기 업데이트\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     new_trackers \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(bbox, frame_height, frame_width, func)\u001b[0m\n\u001b[0;32m     35\u001b[0m expanded_bottom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(frame_height, top \u001b[38;5;241m+\u001b[39m height \u001b[38;5;241m+\u001b[39m expand_height))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 얼굴 영역 추출\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m face_region \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m[expanded_top:expanded_bottom, expanded_left:expanded_right]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecific Person\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# 얼굴 스왑 처리\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     swap_image \u001b[38;5;241m=\u001b[39m func(face_region)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import io\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from inswapper import FaceSwapper\n",
    "\n",
    "base_image = \"../face_recognition/test_hanni2.jpg\"\n",
    "source_image = \"../face_recognition/faces/yunsy.jpg\"\n",
    "target_video = \"hanni.mp4\"\n",
    "\n",
    "# 특정 인물의 이미지를 로드하여 인코딩\n",
    "known_image = face_recognition.load_image_file(base_image)\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# FaceSwapper 클래스 인스턴스 생성\n",
    "face_swapper = FaceSwapper(det_size=(160, 160))\n",
    "\n",
    "# 소스 얼굴 설정 (face_index는 선택 사항)\n",
    "success = face_swapper.set_source_face(source_image)\n",
    "\n",
    "if not success:\n",
    "    print(\"소스 얼굴 설정에 실패했습니다.\")\n",
    "    exit()\n",
    "\n",
    "def wrapper(bbox, frame_height, frame_width, func):\n",
    "\n",
    "    left, top, width, height = bbox\n",
    "    expand_ratio=0.3\n",
    "    expand_width = int(width * expand_ratio)\n",
    "    expand_height = int(height * expand_ratio)\n",
    "\n",
    "    expanded_left = int(max(0, left - expand_width))\n",
    "    expanded_top = int(max(0, top - expand_height))\n",
    "    expanded_right = int(min(frame_width, left + width + expand_width))\n",
    "    expanded_bottom = int(min(frame_height, top + height + expand_height))\n",
    "\n",
    "    # 얼굴 영역 추출\n",
    "    face_region = frame[expanded_top:expanded_bottom, expanded_left:expanded_right]\n",
    "\n",
    "    if name == \"Specific Person\":\n",
    "        # 얼굴 스왑 처리\n",
    "        swap_image = func(face_region)\n",
    "   \n",
    "        # 스왑된 얼굴을 프레임에 적용\n",
    "        frame[expanded_top:expanded_bottom, expanded_left:expanded_right] = swap_image\n",
    "        color = (0, 0, 255)  # 빨간색\n",
    "    elif name == \"Candidate\":\n",
    "        color = (255, 0, 0)  # 파란색\n",
    "    else:\n",
    "        color = (0, 255, 0)  # 초록색\n",
    "\n",
    "    # 사각형 그리기\n",
    "    cv2.rectangle(frame, (expanded_left, expanded_top), (expanded_right, expanded_bottom), color, 2)\n",
    "    # 이름과 거리 표시\n",
    "    cv2.putText(frame, name, (expanded_left, expanded_bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    cv2.putText(frame, f\"Distance: {distance:.2f}\", (expanded_left, expanded_bottom + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "def process_face(face_region):\n",
    "    swap_image = face_swapper.swap_faces_in_image(face_region)\n",
    "    return swap_image if swap_image is not None else face_region\n",
    "\n",
    "def view():\n",
    "\n",
    "    # 비디오 파일 로드\n",
    "    video_capture = cv2.VideoCapture(target_video)\n",
    "\n",
    "    # 변수 초기화\n",
    "    trackers = []\n",
    "    face_names = []\n",
    "    face_distances = []\n",
    "    frame_skip = 12\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        # 비디오에서 한 프레임씩 읽기\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 프레임의 높이와 너비를 가져오기\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            # 추적기와 얼굴 정보 초기화\n",
    "            trackers = []\n",
    "            face_names = []\n",
    "            face_distances = []\n",
    "\n",
    "            # 얼굴 위치와 인코딩 탐지\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "            distances = []\n",
    "            for face_encoding in face_encodings:\n",
    "                # 얼굴 거리 계산\n",
    "                distance = face_recognition.face_distance([known_face_encoding], face_encoding)[0]\n",
    "                distances.append(distance)\n",
    "\n",
    "            # 임계값 설정 (예: 0.46)\n",
    "            tolerance = 0.46\n",
    "\n",
    "            # 거리 기준으로 가장 작은 인덱스 찾기\n",
    "            specific_person_index = None\n",
    "            if len(distances) > 0:\n",
    "                min_distance = min(distances)\n",
    "                if min_distance < tolerance:\n",
    "                    specific_person_index = distances.index(min_distance)\n",
    "\n",
    "            for idx, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):\n",
    "                top, right, bottom, left = face_location\n",
    "                width = right - left\n",
    "                height = bottom - top\n",
    "                bbox = (left, top, width, height)\n",
    "\n",
    "                # 얼굴 거리 계산\n",
    "                distance = distances[idx]\n",
    "\n",
    "                if distance < tolerance:\n",
    "                    if idx == specific_person_index:\n",
    "                        name = \"Specific Person\"\n",
    "                    else:\n",
    "                        name = \"Candidate\"\n",
    "                else:\n",
    "                    name = \"Unknown\"\n",
    "\n",
    "                # 추적기 초기화\n",
    "                tracker = cv2.legacy.TrackerKCF_create()\n",
    "                tracker.init(frame, bbox)\n",
    "                trackers.append(tracker)\n",
    "                face_names.append(name)\n",
    "                face_distances.append(distance)\n",
    "\n",
    "                # 얼굴 처리 및 주석 그리기\n",
    "                wrapper(bbox, frame_height, frame_width, process_face)\n",
    "\n",
    "        else:\n",
    "            # 모든 추적기 업데이트\n",
    "            new_trackers = []\n",
    "            new_face_names = []\n",
    "            new_face_distances = []\n",
    "\n",
    "            for tracker, name, distance in zip(trackers, face_names, face_distances):\n",
    "                success, bbox = tracker.update(frame)\n",
    "                if success:\n",
    "                    bbox = tuple(map(int, bbox))\n",
    "                    new_trackers.append(tracker)\n",
    "                    new_face_names.append(name)\n",
    "                    new_face_distances.append(distance)\n",
    "\n",
    "                    # 얼굴 처리 및 주석 그리기\n",
    "                    wrapper(bbox, frame_height, frame_width, process_face)\n",
    "\n",
    "            # 추적기와 얼굴 정보 업데이트\n",
    "            trackers = new_trackers\n",
    "            face_names = new_face_names\n",
    "            face_distances = new_face_distances\n",
    "\n",
    "        # 비디오 출력\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # 'q' 키를 누르면 종료\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 모든 작업 완료 후 클린업\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = \"../face_recognition/faces/newjeans01_g.jpg\"\n",
    "known_file = \"../face_recognition/test_hanni2.jpg\"\n",
    "target_file = \"../face_recognition/test_yun.jpg\"\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 소스 이미지 로드 (얼굴을 교체할 이미지)\n",
    "source_image = face_recognition.load_image_file(source_file)\n",
    "source_image_rgb = source_image[:, :, ::-1]\n",
    "\n",
    "# 대상 얼굴 이미지 로드 (교체할 얼굴)\n",
    "target_face_image = face_recognition.load_image_file(target_file)\n",
    "target_face_locations = face_recognition.face_locations(target_face_image)\n",
    "if len(target_face_locations) == 0:\n",
    "    print(\"대상 얼굴 이미지에서 얼굴을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 대상 얼굴의 첫 번째 얼굴 선택\n",
    "target_face_location = target_face_locations[0]\n",
    "top_t, right_t, bottom_t, left_t = target_face_location\n",
    "target_face = target_face_image[top_t:bottom_t, left_t:right_t]\n",
    "\n",
    "# 교체할 얼굴 로드 (소스 이미지에서 교체하려는 특정 얼굴)\n",
    "known_face_image = face_recognition.load_image_file(known_file)\n",
    "known_face_encodings = face_recognition.face_encodings(known_face_image)\n",
    "if len(known_face_encodings) == 0:\n",
    "    print(\"교체할 얼굴 이미지에서 얼굴을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "known_face_encoding = known_face_encodings[0]\n",
    "\n",
    "# 소스 이미지에서 모든 얼굴과 인코딩 찾기\n",
    "source_face_locations = face_recognition.face_locations(source_image)\n",
    "source_face_encodings = face_recognition.face_encodings(source_image, source_face_locations)\n",
    "\n",
    "# 소스 이미지의 각 얼굴에 대해 반복\n",
    "for (face_location, face_encoding) in zip(source_face_locations, source_face_encodings):\n",
    "    # 이 얼굴이 교체하려는 얼굴인지 확인\n",
    "    matches = face_recognition.compare_faces([known_face_encoding], face_encoding, tolerance=0.4)\n",
    "\n",
    "    if matches[0]:\n",
    "        # 교체할 얼굴을 찾았습니다.\n",
    "        top, right, bottom, left = face_location\n",
    "        # 대상 얼굴을 교체할 얼굴의 크기에 맞게 조정\n",
    "        face_width = right - left\n",
    "        face_height = bottom - top\n",
    "        target_face_resized = cv2.resize(target_face, (face_width, face_height))\n",
    "\n",
    "        # 소스 이미지에서 얼굴 교체\n",
    "        source_image[top:bottom, left:right] = target_face_resized\n",
    "\n",
    "# 결과 저장\n",
    "cv2.imwrite(\"result.jpg\", cv2.cvtColor(source_image, cv2.COLOR_RGB2BGR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
